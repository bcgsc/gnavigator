{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# purpose: create a tool similar to CEGMA/BUSCO that uses genetic map information to assess \n",
    "#    completeness and quality of an assembly and reporting a simple set of metrics\n",
    "\n",
    "# want to distinguish complete, partial, fragmented, duplicated, poorly mapped, and missing\n",
    "# complete: 95% of sequence is aligned with 95% identity\n",
    "# partial: less than 95% of sequence is aligned to a single scaffold, other 5% unaligned\n",
    "# fragmented: 95% of a sequence is aligned, but over multiple scaffolds\n",
    "## would need to use check_aln in 'report' mode and assess separately\n",
    "## alignment would be reported in \"*.transloc\"\n",
    "# duplicated: as complete, but at multiple locations\n",
    "## alignment would be reported in \"*.mult\"\n",
    "# poorly mapped: as complete, partial, or fragmented, but with less than 95% identity\n",
    "# missing: not aligned by gmap\n",
    "## assessed separately\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import argparse\n",
    "from itertools import groupby\n",
    "from time import localtime, strftime\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    print 'ERROR: The pandas module is required, but was not found. Please install and try again.'\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR DEV ###\n",
    "import numpy as np\n",
    "### END DEV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "# return the sequence from the assembly that corresponds to the cDNA\n",
    "# report if any genetic map cDNAs should be found between cDNAs that are observed\n",
    "# add some wiggle room to the same LG, wrong order category. +/- 25bp?\n",
    "## should be handled by shuffling cDNAs with same cM location\n",
    "# quit upon gmap error\n",
    "# option to delete indices after use\n",
    "# set default %ident for inter- vs intra-species cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_aln(aln, mode):\n",
    "    \"\"\"check the alignment of a gcat map sequence\"\"\"\n",
    "\n",
    "    matches = float(aln.matches)\n",
    "    mismatches = float(aln.mismatches)\n",
    "    qinserts = float(aln.qbaseinsert)\n",
    "    qsize = float(aln.qsize)\n",
    "    qstart = float(aln.qstart)\n",
    "    qend = float(aln.qend)\n",
    "    scaf = str(aln.tname)\n",
    "    cDNA = str(aln.qname)\n",
    "    \n",
    "    seg = qend - qstart\n",
    "    pid = matches / seg\n",
    "    # want to penalize insertions b/c reflects correctness of assembly\n",
    "    pcov = (matches + mismatches - qinserts) / qsize\n",
    "    \n",
    "    if mode == 'assess':\n",
    "        if pid >= 0.95 and pcov >= 0.95:\n",
    "            return (cDNA, scaf, 'Complete')\n",
    "        elif pid >= 0.95 and pcov < 0.95:\n",
    "            if pcov >= 0.5:\n",
    "                return (cDNA, scaf, 'Partial')\n",
    "            else:\n",
    "                return (cDNA, scaf, 'Poorly mapped')\n",
    "        else:\n",
    "            return (cDNA, scaf, 'Poorly mapped')\n",
    "    \n",
    "    elif mode == 'report':\n",
    "        goodb = matches\n",
    "        # want to penalize insertions b/c reflects correctness of assembly\n",
    "        covb = matches + mismatches - qinserts\n",
    "        \n",
    "    return (goodb, covb, seg, qsize, cDNA, scaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_frag(alns):\n",
    "    \"\"\"check if 'chimeric' alignment is good or not\"\"\"\n",
    "    # take in a series of blat alignments and evaluate them together\n",
    "    # TODO extend to assess non-chimeric alignments\n",
    "    ## some cDNAs may be fragmented along >2 scaffolds, with some missing bits in the middle\n",
    "    goodb = 0\n",
    "    covb = 0\n",
    "    seg = 0\n",
    "    qsize = 0\n",
    "    cDNA = ''\n",
    "    scaf = []\n",
    "        \n",
    "    for aln in alns:\n",
    "        this_aln = check_aln(aln, 'report')\n",
    "        # check if a given alignment would otherwise qualify as complete\n",
    "        check_comp = check_aln(aln, 'assess')\n",
    "        if check_comp == 'Complete':\n",
    "            scaf = this_aln[5]\n",
    "            return (cDNA, scaf, 'Complete')\n",
    "        goodb += this_aln[0]\n",
    "        covb += this_aln[1]\n",
    "        seg += this_aln[2]\n",
    "        scaf.append(this_aln[5])\n",
    "    else:\n",
    "        qsize = this_aln[3]\n",
    "        cDNA = this_aln[4]\n",
    "    \n",
    "    pid = goodb / seg\n",
    "    pcov = covb / qsize\n",
    "    \n",
    "    scaf_rep = \";\".join(scaf)\n",
    "    if pid >= 0.95 and pcov >= 0.95:\n",
    "        return (cDNA, scaf_rep, 'Fragmented')\n",
    "    elif pid >= 0.95 and pcov < 0.95:\n",
    "        if pcov > 0.5:\n",
    "            return (cDNA, scaf_rep, 'Partial') # distinguish from partials in a single piece?\n",
    "        else:\n",
    "            return (cDNA, scaf_rep, 'Poorly mapped')\n",
    "    else:\n",
    "        return (cDNA, scaf_rep, 'Poorly mapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dupl(alns):\n",
    "    \"\"\"check if a gcat sequence should be considered duplicated or not based on its multiple alignments\"\"\"\n",
    "    # more than one alignment must be considered complete in order to be duplicated\n",
    "    # one or more partial, fragmented, poorly mapped will not count\n",
    "    cDNA = ''\n",
    "    scaf = []\n",
    "    results = {'Complete':[], 'Partial':[], 'Duplicated':[], 'Poorly mapped':[]}\n",
    "    for aln in alns:\n",
    "        this_aln = check_aln(aln, 'assess')\n",
    "        res = this_aln[-1]\n",
    "        results[res].append(this_aln)\n",
    "        scaf.append(this_aln[1])\n",
    "    else:\n",
    "        cDNA = this_aln[0]\n",
    "\n",
    "    scaf_rep = \";\".join(scaf)\n",
    "    num_complete = len(results['Complete'])\n",
    "    if num_complete == 1:\n",
    "        best_scaf = scaf[0]\n",
    "        return (cDNA, best_scaf, 'Complete')\n",
    "    elif num_complete > 1:\n",
    "        return (cDNA, scaf_rep, 'Duplicated')\n",
    "    else:\n",
    "        if len(results['Partial']) >= 1:\n",
    "            return (cDNA, scaf_rep, 'Partial')\n",
    "        else:\n",
    "            return (cDNA, scaf_rep, 'Poorly mapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_aligned(uniqA, duplA, tlocA):\n",
    "    \"\"\"count how many seqs have any alignment whatsoever\"\"\"\n",
    "    aligned = set()\n",
    "    for rec in uniqA.qname.unique():\n",
    "        aligned.add(rec)\n",
    "    for rec in duplA.qname.unique():\n",
    "        aligned.add(rec)\n",
    "    for rec in tlocA.qname.unique():\n",
    "        aligned.add(rec)\n",
    "        \n",
    "    return len(aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_LG(query, genetic_map):\n",
    "    \"\"\"check if cDNAs are from the same LG\"\"\"\n",
    "    # query is a pandas array of a single scaffold's alignments\n",
    "    # genetic_map is a pandas array of LG\\tcM\\tcDNA\n",
    "    # assume for now that cDNA is in genetic_map$cDNA\n",
    "    # returns 'same LG, right order', 'same LG, wrong order', or 'different LG'\n",
    "    refs = query.qname.tolist()\n",
    "    thisMap = genetic_map[genetic_map.cDNA.isin(refs)]\n",
    "    numLG = len(thisMap.LG.unique())\n",
    "    scaf = str(query.tname.unique()[0])\n",
    "    fwdA = query.sort_values(['tstart'])\n",
    "    fwdL = fwdA.qname.tolist()\n",
    "    revA = query.sort_values(['tstart'], ascending=False)\n",
    "    revL = revA.qname.tolist()\n",
    "    mapL = thisMap.cDNA.tolist()\n",
    "    cDNA_names = \";\".join(fwdL)\n",
    "    if len(thisMap) == 2:\n",
    "        if numLG == 1:\n",
    "            return (scaf, cDNA_names, 'Same LG, right order')\n",
    "        else:\n",
    "            return (scaf, cDNA_names, 'Different LG')\n",
    "    else:\n",
    "        if numLG == 1:\n",
    "            # comparing two lists of the same length will return True if order is the same\n",
    "            # compare both forward and reverse orders\n",
    "            if mapL == fwdL:\n",
    "                return (scaf, cDNA_names, 'Same LG, right order')\n",
    "            elif mapL == revL:\n",
    "                return (scaf, cDNA_names, 'Same LG, right order')\n",
    "            # some GM features have the same position in cM\n",
    "            # shuffle such features and check if they could match the alignments\n",
    "            # handle cases where only one set of features being evaluated has the same cM position\n",
    "            ## I haven't seen more than that, and would be much trickier to handle if so\n",
    "            else:\n",
    "                dup_cm = thisMap[thismap.duplicated('cM', False)]\n",
    "                \n",
    "                #else:\n",
    "                #    pass\n",
    "                #    return (scaf, cDNA_names, 'Same LG, wrong order')\n",
    "        else:\n",
    "            return (scaf, cDNA_names, 'Different LG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'thisMap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-ba35a3b70f9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### FOR DEV ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#check_LG(uMap.tname.isin(['90822']), mapDat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mthisMap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#for i in uMap.tname.unique():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#    print uMap.tname.isin([i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'thisMap' is not defined"
     ]
    }
   ],
   "source": [
    "### FOR DEV ###\n",
    "#check_LG(uMap.tname.isin(['90822']), mapDat)\n",
    "thisMap\n",
    "#for i in uMap.tname.unique():\n",
    "#    print uMap.tname.isin([i])\n",
    "### END DEV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jira_formatter(num_pct_tuple):\n",
    "    # num_pct_tuple is tuple of (num, pct)\n",
    "    num = num_pct_tuple[0]\n",
    "    pct = num_pct_tuple[1]\n",
    "    outbuff = str(num) + \" \" + \"(\" + str(pct) + \"%)\"\n",
    "    return outbuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_formatter(results_tuple):\n",
    "    # results_tuple is from one of the check* functions\n",
    "    # (cDNA, scaffold, status), or (cDNA, scaffold1;scaffold2..., status)\n",
    "    nam = results_tuple[0]\n",
    "    scaf = results_tuple[1].split(\";\")\n",
    "    stat = results_tuple[2]\n",
    "    \n",
    "    for entry in scaf:\n",
    "        outbuff = \"\\t\".join([nam, stat, entry])\n",
    "        yield outbuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LG_table_formatter(results_tuple):\n",
    "    # results_tuple is from one of the check* functions\n",
    "    # (cDNA, scaffold, status), or (cDNA, scaffold1;scaffold2..., status)\n",
    "    nam = results_tuple[0]\n",
    "    cDNA = \" \".join(results_tuple[1].split(\";\"))\n",
    "    stat = results_tuple[2]\n",
    "    \n",
    "    outbuff = \"\\t\".join([nam, cDNA, stat])\n",
    "    yield outbuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fasta_iter\n",
    "#\n",
    "#   modified from code written by brentp and retrieved from https://www.biostars.org/p/710/ on May 5, 2015\n",
    "#   given a fasta file. yield tuples of header, sequence\n",
    "def fasta_iter(fasta_name):\n",
    "    # ditch the boolean (x[0]) and just keep the header or sequence since\n",
    "    # we know they alternate.\n",
    "    faiter = (x[1] for x in groupby(fasta_name, lambda line: line[0] == \">\"))\n",
    "    for header in faiter:\n",
    "        # drop the \">\"\n",
    "        header = header.next()[1:].strip()\n",
    "        # join all sequence lines to one.\n",
    "        seq = \"\".join(s.strip() for s in faiter.next())\n",
    "        yield header, seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing(fasta, res_dict):\n",
    "    # fasta is cDNA fasta\n",
    "    # res_dict is results dictionary like cDNA_res\n",
    "    # trim_flag corresponds to -a flag, passed to fasta_iter\n",
    "    ## will trim GenBank-style revision code from sequence IDs\n",
    "    cDNA_set = set()\n",
    "    with open(fasta, 'r') as infile:\n",
    "        for rec in fasta_iter(infile):\n",
    "            seqid = rec[0]\n",
    "            seqid_only = seqid.split(\" \")[0]\n",
    "            cDNA_set.add(seqid_only)\n",
    "    tot_cDNA = len(cDNA_set)\n",
    "\n",
    "    detected = set()\n",
    "    for key, value in res_dict.items():\n",
    "        resID = set([x[0] for x in value])\n",
    "        detected = detected.union(resID)\n",
    "\n",
    "    missing = cDNA_set.difference(detected)\n",
    "    missingL = [(x, 'NA', 'Missing') for x in missing]\n",
    "    \n",
    "    return (missingL, tot_cDNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_time():\n",
    "    rep = ' '.join([\"Current time:\", strftime(\"%Y-%m-%d %H:%M:%S\", localtime())])\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parser\n",
    "parser = argparse.ArgumentParser(description='Assess assembly quality and completeness using cDNA sequences')\n",
    "parser.add_argument('cDNA', help='FASTA file of cDNA sequences to align to assembly') # cDNA sequence fasta\n",
    "parser.add_argument('genome', help='FASTA file of genome assembly to assess')\n",
    "parser.add_argument('-p', '--prefix', help='Prefix to use for intermediate and output files [gnavigator]', default='gnavigator') # prefix\n",
    "parser.add_argument('-d', '--db_dir', help='Path to directory containing prebuilt GMAP index [optional]') # gmap db dir\n",
    "parser.add_argument('-n', '--db_name', help='Name of prebuilt GMAP index [optional]') # gmap db name\n",
    "parser.add_argument('-t', '--threads', help='Number of threads for GMAP alignment [1]', action='store', default='1')\n",
    "parser.add_argument('-m', '--genetic_map', help='Genetic map file as tsv with LG:cDNA pairs [optional]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process args\n",
    "args = parser.parse_args()\n",
    "cDNA = args.cDNA\n",
    "genome = args.genome\n",
    "prefix = args.prefix\n",
    "threads = args.threads\n",
    "\n",
    "if args.db_dir:\n",
    "    dbDir = args.db_dir\n",
    "else:\n",
    "    dbDir = ''.join([os.getcwd(), '/', prefix, '-gmap-index-dir'])\n",
    "if args.db_name:\n",
    "    dbName = args.db_name\n",
    "else:\n",
    "    dbName = '-'.join([prefix, 'gmap-index'])\n",
    "if args.genetic_map:\n",
    "    check_gm = True\n",
    "    gmfile = args.genetic_map\n",
    "else:\n",
    "    check_gm = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path to this script, and assume that the gmap sh scripts are there too\n",
    "gnavigator_path = re.sub('gnavigator.py', '', os.path.realpath(__file__))\n",
    "\n",
    "# check if alignments have already been done\n",
    "checkU = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".uniq\"]))\n",
    "checkM = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".mult\"]))\n",
    "checkD = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".transloc\"]))\n",
    "if checkU or checkM or checkD:\n",
    "    print \"\\n=== Skipping GMAP alignment stage ===\"\n",
    "    print \"Gnavigator found pre-existing GMAP alignment results. Will use the following files:\"\n",
    "    if checkU:\n",
    "        print ''.join([os.getcwd(), '/', prefix, \".uniq\"])\n",
    "    if checkM:\n",
    "        print ''.join([os.getcwd(), '/', prefix, \".mult\"])\n",
    "    if checkD:\n",
    "        print ''.join([os.getcwd(), '/', prefix, \".transloc\"])\n",
    "    print report_time()\n",
    "else:\n",
    "    # detect pre-existing index, use this check later (ref153positions is final index file created)\n",
    "    checkI = os.path.isfile(''.join([os.getcwd(), '/', prefix, '-gmap-index-dir/',\n",
    "                                     prefix, '-gmap-index/', prefix, '-gmap-index.ref153positions']))\n",
    "    # make log file names\n",
    "    indexlog = \"-\".join([prefix, \"gmap\", \"index.log\"])\n",
    "    alignlog = \"-\".join([prefix, \"gmap\", \"alignment.log\"])\n",
    "    # check if user supplied an index\n",
    "    if args.db_dir and args.db_name:\n",
    "        print \"\\n=== Skipping GMAP index construction ===\"\n",
    "        print \"Gnavigator will use the user-specified index:\"\n",
    "        print args.db_dir\n",
    "        print report_time()\n",
    "    # if not, check if index made already\n",
    "    elif checkI:\n",
    "        print \"\\n=== Skipping GMAP index construction ===\"\n",
    "        print \"Gnavigator found a pre-existing GMAP index:\"\n",
    "        print ''.join([os.getcwd(), '/', prefix, '-gmap-index-dir'])\n",
    "        print report_time()      \n",
    "    # otherwise, make gmap index\n",
    "    else:\n",
    "        print \"\\n=== Building GMAP database ===\"\n",
    "        print report_time()\n",
    "        try:\n",
    "            subprocess.check_call([gnavigator_path + '/build-index.sh', dbDir, dbName, genome, indexlog])\n",
    "        except subprocess.CalledProcessError:\n",
    "            print '\\nERROR: Failed to build GMAP index.'\n",
    "            print 'Make sure that build-index.sh is in the same directory as gnavigator and genome file exists.'\n",
    "            sys.exit(1)\n",
    "        print \"Done!\"\n",
    "    # run gmap alignment\n",
    "    print \"\\n=== Performing GMAP alignments ===\"\n",
    "    print report_time()\n",
    "    try:\n",
    "        subprocess.check_call([gnavigator_path + '/run-gmap.sh', dbDir, dbName, threads, prefix, cDNA, alignlog])\n",
    "    except subprocess.CalledProcessError:\n",
    "        print '\\nERROR: Failed to perform GMAP alignment.'\n",
    "        print 'Make sure that run-gmap.sh is in the same directory as gnavigator and cDNA file exists.'\n",
    "        sys.exit(1)\n",
    "    print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which alignment files were produced\n",
    "checkU = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".uniq\"]))\n",
    "checkM = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".mult\"]))\n",
    "checkD = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".transloc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data and define extent\n",
    "col_names = ['matches', 'mismatches', 'repmatches', 'ncount', 'qnuminsert', 'qbaseinsert', 'tnuminsert', \n",
    "             'tbaseinsert', 'strand', 'qname', 'qsize', 'qstart', 'qend', 'tname', 'tsize', 'tstart', 'tend',\n",
    "             'blockcount', 'blocksizes', 'qstarts', 'tstarts']\n",
    "if checkU:\n",
    "    uniqDat = pd.read_csv('.'.join([prefix, 'uniq']), sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "if checkM:\n",
    "    duplDat = pd.read_csv('.'.join([prefix, 'mult']), sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "if checkD:\n",
    "    tlocDat = pd.read_csv('.'.join([prefix, 'transloc']), sep='\\t', comment='#', low_memory=False, header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR DEV ###\n",
    "# read in the data and define extent\n",
    "col_names = ['matches', 'mismatches', 'repmatches', 'ncount', 'qnuminsert', 'qbaseinsert', 'tnuminsert', \n",
    "             'tbaseinsert', 'strand', 'qname', 'qsize', 'qstart', 'qend', 'tname', 'tsize', 'tstart', 'tend',\n",
    "             'blockcount', 'blocksizes', 'qstarts', 'tstarts']\n",
    "\n",
    "uniqDat = pd.read_csv('/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/runs/sitka-new-strategy-postLINKS-95.uniq', sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "duplDat = pd.read_csv('/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/runs/sitka-new-strategy-postLINKS-95.mult', sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "tlocDat = pd.read_csv('/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/runs/sitka-new-strategy-postLINKS-95.transloc', sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "### END DEV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR DEV ###\n",
    "# alternate data with numeric scaffold IDs\n",
    "# read in the data and define extent\n",
    "col_names = ['matches', 'mismatches', 'repmatches', 'ncount', 'qnuminsert', 'qbaseinsert', 'tnuminsert', \n",
    "             'tbaseinsert', 'strand', 'qname', 'qsize', 'qstart', 'qend', 'tname', 'tsize', 'tstart', 'tend',\n",
    "             'blockcount', 'blocksizes', 'qstarts', 'tstarts']\n",
    "\n",
    "uniqDat = pd.read_csv('/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/tests/WS-v1-tigmint-ARCS-Sealer_cobbler-rails-a500s0.99_1000plus.uniq', sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "duplDat = pd.read_csv('/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/tests/WS-v1-tigmint-ARCS-Sealer_cobbler-rails-a500s0.99_1000plus.mult', sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "tlocDat = pd.read_csv('/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/tests/WS-v1-tigmint-ARCS-Sealer_cobbler-rails-a500s0.99_1000plus.transloc', sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "### END DEV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in genetic map, if supplied\n",
    "# format for spruce map is LG\\tcM\\tcDNA\n",
    "if check_gm:\n",
    "    if not checkU:\n",
    "        print 'WARNING: There were no uniquely-aligned cDNAs detected, so the genetic map analysis will not be performed'\n",
    "    mapDat = pd.read_csv(gmfile, sep=\"\\t\", comment='#', low_memory=False, header=None, names=['LG', 'cM', 'cDNA'])\n",
    "    # limit genetic map analysis to complete (i.e. single) cDNAs to improve confidence\n",
    "    map_cDNA = set(mapDat.cDNA.tolist())\n",
    "    uniqDatMap = uniqDat[uniqDat.qname.isin(map_cDNA)]\n",
    "    uMap = uniqDatMap[uniqDatMap.tname.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LG</th>\n",
       "      <th>cM</th>\n",
       "      <th>cDNA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LG01</td>\n",
       "      <td>0.825</td>\n",
       "      <td>GQ0257_J11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LG01</td>\n",
       "      <td>0.825</td>\n",
       "      <td>GQ03112_F13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LG01</td>\n",
       "      <td>0.825</td>\n",
       "      <td>GQ03107_A10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LG01</td>\n",
       "      <td>1.230</td>\n",
       "      <td>GQ03212_C22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LG01</td>\n",
       "      <td>1.230</td>\n",
       "      <td>GQ03311_K12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LG01</td>\n",
       "      <td>2.188</td>\n",
       "      <td>GQ03007_B12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LG01</td>\n",
       "      <td>2.188</td>\n",
       "      <td>GQ03326_J11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LG01</td>\n",
       "      <td>2.495</td>\n",
       "      <td>GQ02824_O24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LG01</td>\n",
       "      <td>2.495</td>\n",
       "      <td>GQ03806_M07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LG01</td>\n",
       "      <td>3.213</td>\n",
       "      <td>GQ03303_A18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LG01</td>\n",
       "      <td>3.213</td>\n",
       "      <td>GQ04108_N14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LG01</td>\n",
       "      <td>4.246</td>\n",
       "      <td>GQ03303_I14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LG01</td>\n",
       "      <td>4.246</td>\n",
       "      <td>GQ02815_D18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LG01</td>\n",
       "      <td>4.246</td>\n",
       "      <td>GQ03237_K12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>LG01</td>\n",
       "      <td>23.775</td>\n",
       "      <td>GQ02813_E14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>LG01</td>\n",
       "      <td>23.775</td>\n",
       "      <td>GQ02757_D12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>LG01</td>\n",
       "      <td>23.775</td>\n",
       "      <td>GQ02510_E13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>LG01</td>\n",
       "      <td>29.368</td>\n",
       "      <td>GQ03206_B04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>LG01</td>\n",
       "      <td>29.368</td>\n",
       "      <td>GQ03102_E15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>LG01</td>\n",
       "      <td>52.203</td>\n",
       "      <td>GQ03315_E04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>LG01</td>\n",
       "      <td>52.203</td>\n",
       "      <td>GQ03311_N20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>LG01</td>\n",
       "      <td>57.503</td>\n",
       "      <td>GQ04113_H14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>LG01</td>\n",
       "      <td>57.503</td>\n",
       "      <td>GQ027103_B09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>LG01</td>\n",
       "      <td>67.192</td>\n",
       "      <td>GQ04003_D03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>LG01</td>\n",
       "      <td>67.192</td>\n",
       "      <td>GQ03208_E24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>LG01</td>\n",
       "      <td>85.284</td>\n",
       "      <td>GQ0071_P18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>LG01</td>\n",
       "      <td>85.284</td>\n",
       "      <td>GQ04104_C02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>LG01</td>\n",
       "      <td>85.284</td>\n",
       "      <td>GQ03217_H19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>LG01</td>\n",
       "      <td>87.168</td>\n",
       "      <td>GQ03312_M12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>LG01</td>\n",
       "      <td>87.168</td>\n",
       "      <td>GQ0208_I20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>LG01</td>\n",
       "      <td>131.881</td>\n",
       "      <td>GQ03113_J11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>LG01</td>\n",
       "      <td>131.881</td>\n",
       "      <td>GQ0174_E09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>LG01</td>\n",
       "      <td>138.584</td>\n",
       "      <td>GQ02819_P12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>LG01</td>\n",
       "      <td>138.584</td>\n",
       "      <td>GQ03814_P23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>LG01</td>\n",
       "      <td>139.210</td>\n",
       "      <td>GQ0015_N11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>LG01</td>\n",
       "      <td>139.210</td>\n",
       "      <td>GQ0202_I09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>LG01</td>\n",
       "      <td>139.305</td>\n",
       "      <td>GQ03003_G17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>LG01</td>\n",
       "      <td>139.305</td>\n",
       "      <td>WS00829_C22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>LG01</td>\n",
       "      <td>141.361</td>\n",
       "      <td>GQ04012_K18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>LG01</td>\n",
       "      <td>141.361</td>\n",
       "      <td>GQ02803_L21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>LG01</td>\n",
       "      <td>145.187</td>\n",
       "      <td>GQ03120_N11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>LG01</td>\n",
       "      <td>145.187</td>\n",
       "      <td>WS00727_N20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>LG01</td>\n",
       "      <td>163.999</td>\n",
       "      <td>GQ03602_N02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>LG01</td>\n",
       "      <td>163.999</td>\n",
       "      <td>GQ03501_O22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>LG01</td>\n",
       "      <td>164.832</td>\n",
       "      <td>GQ04101_I01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>LG01</td>\n",
       "      <td>164.832</td>\n",
       "      <td>GQ03222_O10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>LG01</td>\n",
       "      <td>165.013</td>\n",
       "      <td>GQ02810_J16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>LG01</td>\n",
       "      <td>165.013</td>\n",
       "      <td>GQ03605_F01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>LG01</td>\n",
       "      <td>166.218</td>\n",
       "      <td>GQ03212_C15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>LG01</td>\n",
       "      <td>166.218</td>\n",
       "      <td>GQ03238_O10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>LG01</td>\n",
       "      <td>166.218</td>\n",
       "      <td>GQ03222_O12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>LG01</td>\n",
       "      <td>166.218</td>\n",
       "      <td>GQ03410_I06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>LG01</td>\n",
       "      <td>167.693</td>\n",
       "      <td>GQ03609_K13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>LG01</td>\n",
       "      <td>167.693</td>\n",
       "      <td>GQ03234_J22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>LG01</td>\n",
       "      <td>168.935</td>\n",
       "      <td>GQ02822_N04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>LG01</td>\n",
       "      <td>168.935</td>\n",
       "      <td>GQ03224_B01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>LG01</td>\n",
       "      <td>170.154</td>\n",
       "      <td>GQ03107_L19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>LG01</td>\n",
       "      <td>170.154</td>\n",
       "      <td>GQ02823_G11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>LG01</td>\n",
       "      <td>171.092</td>\n",
       "      <td>GQ03707_D22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>LG01</td>\n",
       "      <td>171.092</td>\n",
       "      <td>GQ03611_I10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LG       cM          cDNA\n",
       "6    LG01    0.825    GQ0257_J11\n",
       "7    LG01    0.825   GQ03112_F13\n",
       "8    LG01    0.825   GQ03107_A10\n",
       "17   LG01    1.230   GQ03212_C22\n",
       "18   LG01    1.230   GQ03311_K12\n",
       "23   LG01    2.188   GQ03007_B12\n",
       "24   LG01    2.188   GQ03326_J11\n",
       "25   LG01    2.495   GQ02824_O24\n",
       "26   LG01    2.495   GQ03806_M07\n",
       "28   LG01    3.213   GQ03303_A18\n",
       "29   LG01    3.213   GQ04108_N14\n",
       "31   LG01    4.246   GQ03303_I14\n",
       "32   LG01    4.246   GQ02815_D18\n",
       "33   LG01    4.246   GQ03237_K12\n",
       "122  LG01   23.775   GQ02813_E14\n",
       "123  LG01   23.775   GQ02757_D12\n",
       "124  LG01   23.775   GQ02510_E13\n",
       "143  LG01   29.368   GQ03206_B04\n",
       "144  LG01   29.368   GQ03102_E15\n",
       "210  LG01   52.203   GQ03315_E04\n",
       "211  LG01   52.203   GQ03311_N20\n",
       "228  LG01   57.503   GQ04113_H14\n",
       "229  LG01   57.503  GQ027103_B09\n",
       "248  LG01   67.192   GQ04003_D03\n",
       "249  LG01   67.192   GQ03208_E24\n",
       "323  LG01   85.284    GQ0071_P18\n",
       "324  LG01   85.284   GQ04104_C02\n",
       "325  LG01   85.284   GQ03217_H19\n",
       "330  LG01   87.168   GQ03312_M12\n",
       "331  LG01   87.168    GQ0208_I20\n",
       "..    ...      ...           ...\n",
       "546  LG01  131.881   GQ03113_J11\n",
       "547  LG01  131.881    GQ0174_E09\n",
       "575  LG01  138.584   GQ02819_P12\n",
       "576  LG01  138.584   GQ03814_P23\n",
       "583  LG01  139.210    GQ0015_N11\n",
       "584  LG01  139.210    GQ0202_I09\n",
       "586  LG01  139.305   GQ03003_G17\n",
       "587  LG01  139.305   WS00829_C22\n",
       "593  LG01  141.361   GQ04012_K18\n",
       "594  LG01  141.361   GQ02803_L21\n",
       "605  LG01  145.187   GQ03120_N11\n",
       "606  LG01  145.187   WS00727_N20\n",
       "671  LG01  163.999   GQ03602_N02\n",
       "672  LG01  163.999   GQ03501_O22\n",
       "674  LG01  164.832   GQ04101_I01\n",
       "675  LG01  164.832   GQ03222_O10\n",
       "677  LG01  165.013   GQ02810_J16\n",
       "678  LG01  165.013   GQ03605_F01\n",
       "691  LG01  166.218   GQ03212_C15\n",
       "692  LG01  166.218   GQ03238_O10\n",
       "693  LG01  166.218   GQ03222_O12\n",
       "694  LG01  166.218   GQ03410_I06\n",
       "711  LG01  167.693   GQ03609_K13\n",
       "712  LG01  167.693   GQ03234_J22\n",
       "720  LG01  168.935   GQ02822_N04\n",
       "721  LG01  168.935   GQ03224_B01\n",
       "729  LG01  170.154   GQ03107_L19\n",
       "730  LG01  170.154   GQ02823_G11\n",
       "735  LG01  171.092   GQ03707_D22\n",
       "736  LG01  171.092   GQ03611_I10\n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### FOR DEV ###\n",
    "#print cDNA_res['Complete'][:6]\n",
    "#print mapDat[:30]\n",
    "#for i in enumerate(map_cDNA):\n",
    "#    print i\n",
    "#print 'GQ03719_E22' in cDNA_res['Complete']\n",
    "#for i in cDNA_res['Complete']:\n",
    "#    if 'GQ03901_D14' in i:\n",
    "#        print i\n",
    "\n",
    "lg01 = mapDat[mapDat.LG.isin(['LG01'])]\n",
    "lg01cm = lg01[lg01.duplicated('cM', False)]\n",
    "\n",
    "lg01cm\n",
    "#print uniqDatMap[:6]\n",
    "#print len(uMap)\n",
    "### FOR DEV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup counters\n",
    "cDNA_res = {'Complete':[], 'Duplicated':[], 'Partial':[], 'Fragmented':[], 'Poorly mapped':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR DEV ###\n",
    "checkU = checkM = checkD = True\n",
    "### END DEV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply check_complete to whole set\n",
    "if checkU:\n",
    "    for rec in uniqDat.itertuples():\n",
    "        res = check_aln(rec, 'assess')\n",
    "        cDNA_res[res[2]].append(res) # append results tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply check_frag to whole set\n",
    "if checkD:\n",
    "    for qry in tlocDat.qname.unique():\n",
    "        this_qry = tlocDat[tlocDat.qname == qry]\n",
    "        frags = []\n",
    "        for rec in this_qry.itertuples():\n",
    "            frags.append(rec)\n",
    "\n",
    "        res = check_frag(frags)\n",
    "        cDNA_res[res[2]].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply check_dupl to whole set\n",
    "if checkM:\n",
    "    for qry in duplDat.qname.unique():\n",
    "        this_qry = duplDat[duplDat.qname == qry]\n",
    "        frags = []\n",
    "        for rec in this_qry.itertuples():\n",
    "            frags.append(rec)\n",
    "\n",
    "        res = check_dupl(frags)\n",
    "        cDNA_res[res[2]].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR DEV ###\n",
    "cDNA = '/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/tests/GCAT_WS-3.3.cluseq.noGaps.simple.fa'\n",
    "gmfile = '/projects/spruceup/Collaborators_spruce_resources/spruce-composite-genetic-map.tsv'\n",
    "trim = True\n",
    "check_gm = True\n",
    "### END DEV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total number of query sequences\n",
    "check_missing = find_missing(cDNA, cDNA_res)\n",
    "TOT = check_missing[1]\n",
    "cDNA_res['Missing'] = check_missing[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out cDNA:scaffold mappings\n",
    "header = \"\\t\".join([\"# cDNA ID\", \"Status\", \"Scaffold\"])\n",
    "full_out = \"-\".join([prefix, \"full-cDNA-results-table.tsv\"])\n",
    "with open(full_out, \"w\") as outfile:\n",
    "    print >> outfile, header\n",
    "    for status, result in cDNA_res.items():\n",
    "        for res in result:\n",
    "            for t in table_formatter(res):\n",
    "                print >> outfile, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc percentages and report results\n",
    "num_complete = len(cDNA_res['Complete'])\n",
    "num_duplicated = len(cDNA_res['Duplicated'])\n",
    "num_partial = len(cDNA_res['Partial'])\n",
    "num_fragmented = len(cDNA_res['Fragmented'])\n",
    "num_poor = len(cDNA_res['Poorly mapped'])\n",
    "num_missing = len(cDNA_res['Missing'])\n",
    "\n",
    "rate_complete = float(num_complete) / float(TOT)\n",
    "rate_duplicated = float(num_duplicated) / float(TOT)\n",
    "rate_partial = float(num_partial) / float(TOT)\n",
    "rate_fragmented = float(num_fragmented) / float(TOT)\n",
    "rate_poor = float(num_poor) / float(TOT)\n",
    "rate_missing = float(num_missing) / float(TOT)\n",
    "\n",
    "pct_complete = round(100.0 * rate_complete, 2)\n",
    "pct_duplicated = round(100.0 * rate_duplicated, 2)\n",
    "pct_partial = round(100.0 * rate_partial, 2)\n",
    "pct_fragmented = round(100 * rate_fragmented, 2)\n",
    "pct_poor = round(100 * rate_poor, 2)\n",
    "pct_missing = round(100 * rate_missing, 2)\n",
    "\n",
    "# report if the right number of sequences have a result\n",
    "num_counted = sum([num_complete, num_duplicated, num_fragmented, num_partial, num_poor, num_missing])\n",
    "rate_counted = float(num_counted) / float(TOT)\n",
    "pct_counted = round(100 * rate_counted, 2)\n",
    "\n",
    "# write to tsv\n",
    "tsvout = \"-\".join([prefix, \"results.tsv\"])\n",
    "with open(tsvout, \"w\") as outfile:\n",
    "    header = \"\\t\".join([\"\", \"Complete\", \"Duplicated\", \"Fragmented\", \"Partial\", \"Poorly Mapped\", \"Missing\", \"Total cDNAs searched\"])\n",
    "    nums = \"\\t\".join([str(x) for x in [\"Number\", num_complete, num_duplicated, num_fragmented, num_partial, num_poor, num_missing, num_counted]])\n",
    "    pcts = \"\\t\".join([str(x) for x in [\"Percent\", pct_complete, pct_duplicated, pct_fragmented, pct_partial, pct_poor, pct_missing, pct_counted]])\n",
    "\n",
    "    print >> outfile, header\n",
    "    print >> outfile, nums\n",
    "    print >> outfile, pcts\n",
    "\n",
    "jiraout = \"-\".join([prefix, \"results.jira\"])\n",
    "with open(jiraout, \"w\") as outfile:\n",
    "    header = \"||\".join([\"\", \"Complete\", \"Duplicated\", \"Fragmented\", \"Partial\", \"Poorly Mapped\", \"Missing\", \"Total cDNAs searched\", \"\"])\n",
    "    nums = [num_complete, num_duplicated, num_fragmented, num_partial, num_poor, num_missing, num_counted]\n",
    "    pcts = [pct_complete, pct_duplicated, pct_fragmented, pct_partial, pct_poor, pct_missing, pct_counted]\n",
    "    res = \"|\" + \"|\".join([jira_formatter(x) for x in zip(nums, pcts)]) + \"|\"\n",
    "    \n",
    "    print >> outfile, header\n",
    "    print >> outfile, res\n",
    "\n",
    "# print to STDOUT\n",
    "print \"\\n=== GNAVIGATOR cDNA RESULTS ===\"\n",
    "print \"%s (%s%%) complete sequences\" % (num_complete, pct_complete)\n",
    "print \"%s (%s%%) duplicated sequences\" % (num_duplicated, pct_duplicated)\n",
    "print \"%s (%s%%) fragmented sequences\" % (num_fragmented, pct_fragmented)\n",
    "print \"%s (%s%%) partial sequences\" % (num_partial, pct_partial)\n",
    "print \"%s (%s%%) poorly mapped sequences\" % (num_poor, pct_poor)\n",
    "print \"%s (%s%%) missing sequences\" % (num_missing, pct_missing)\n",
    "print \"%s (%s%%) sequences were evaluated\" % (num_counted, pct_counted)\n",
    "print report_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-a0e83df0b53c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mthisScaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muMap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muMap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_LG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthisScaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapDat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Same LG, right order'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mgm_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'goodLG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "# apply check_LG to whole uniq set\n",
    "if check_gm:\n",
    "    # check if there's anything to work with\n",
    "    if len(uniqDatMap) == 0:\n",
    "        print \"ERROR: There are no cDNAs from the genetic map to evaluate.\"\n",
    "        print \"This can happen if the cDNA sequence IDs do not match those in the genetic map.\"\n",
    "        sys.exit(2)\n",
    "    gm_res = {'goodLG':[], 'WO_LG':[], 'diffLG':[]}\n",
    "    #num_goodLG = 0 # same LG, right order\n",
    "    #num_WO_LG = 0 # same LG, wrong order\n",
    "    #num_diffLG = 0 # different LG\n",
    "\n",
    "    for rec in uMap.tname.unique():\n",
    "        thisScaf = uMap[uMap.tname.isin([rec])]\n",
    "        res = check_LG(thisScaf, mapDat)\n",
    "        rep = res[2]\n",
    "        if rep == 'Same LG, right order':\n",
    "            gm_res['goodLG'].append(res)\n",
    "            #num_goodLG += 1\n",
    "        elif rep == 'Same LG, wrong order':\n",
    "            gm_res['WO_LG'].append(res)\n",
    "            #num_WO_LG += 1\n",
    "        elif rep == 'Different LG':\n",
    "            gm_res['diffLG'].append(res)\n",
    "            #num_diffLG += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR DEV ###\n",
    "print num_goodLG\n",
    "print len(uniqDatMap)\n",
    "uniqDat[:6]\n",
    "### END DEV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write cDNA:scaffold LG results to file\n",
    "if check_gm:\n",
    "    header = \"\\t\".join([\"# Scaffold\", \"cDNA IDs\", \"Status\"])\n",
    "    full_out = \"-\".join([prefix, \"full-genetic-map-results-table.tsv\"])\n",
    "    with open(full_out, \"w\") as outfile:\n",
    "        print >> outfile, header\n",
    "        for status, result in gm_res.items():\n",
    "            for res in result:\n",
    "                for t in LG_table_formatter(res):\n",
    "                    print >> outfile, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report summary of genetic map results\n",
    "if check_gm:\n",
    "    num_scaff_toCheck = len(uMap.tname.unique())\n",
    "    num_goodLG = len(gm_res['goodLG'])\n",
    "    num_WO_LG = len(gm_res['WO_LG'])\n",
    "    num_diffLG = len(gm_res['diffLG'])\n",
    "    num_scaff_checked = num_goodLG + num_WO_LG + num_diffLG\n",
    "    if num_scaff_toCheck == num_scaff_checked:\n",
    "        rate_LGscaff = float(num_scaff_checked) / float(TOT)\n",
    "        rate_goodLG = float(num_goodLG) / float(num_scaff_checked)\n",
    "        rate_WO_LG = float(num_WO_LG) / float(num_scaff_checked)\n",
    "        rate_diffLG = float(num_diffLG) / float(num_scaff_checked)\n",
    "\n",
    "        pct_LGscaff = round(100.0 * rate_LGscaff, 2) \n",
    "        pct_goodLG = round(100.0 * rate_goodLG, 2)\n",
    "        pct_WO_LG = round(100.0 * rate_WO_LG, 2)\n",
    "        pct_diffLG = round(100.0 * rate_diffLG, 2)\n",
    "\n",
    "    else:\n",
    "        print 'Not all scaffolds to be checked against genetic map were successfully checked.'\n",
    "        print 'Maybe something is wrong with the input data?'\n",
    "        print report_time()\n",
    "        sys.exit(2)\n",
    "    \n",
    "    # write to tsv\n",
    "    tsvout = \"-\".join([prefix, \"genetic-map-results.tsv\"])\n",
    "    with open(tsvout, \"w\") as outfile:\n",
    "        header = \"\\t\".join([\"\", \"Same LG, right order\", \"Same LG, wrong order\", \"Different LG\", \"Total scaffolds analyzed\"])\n",
    "        nums = \"\\t\".join([str(x) for x in [\"Number\", num_goodLG, num_WO_LG, num_diffLG, num_scaff_checked]])\n",
    "        pcts = \"\\t\".join([str(x) for x in [\"Percent\", pct_goodLG, pct_WO_LG, pct_diffLG, pct_LGscaff]])\n",
    "\n",
    "        print >> outfile, header\n",
    "        print >> outfile, nums\n",
    "        print >> outfile, pcts\n",
    "\n",
    "    jiraout = \"-\".join([prefix, \"genetic-map-results.jira\"])\n",
    "    with open(jiraout, \"w\") as outfile:\n",
    "        header = \"||\".join([\"\", \"Same LG, right order\", \"Same LG, wrong order\", \"Different LG\", \"Total scaffolds analyzed\", \"\"])\n",
    "        nums = [num_goodLG, num_WO_LG, num_diffLG, num_scaff_checked]\n",
    "        pcts = [pct_goodLG, pct_WO_LG, pct_diffLG, pct_LGscaff]\n",
    "        res = \"|\" + \"|\".join([jira_formatter(x) for x in zip(nums, pcts)]) + \"|\"\n",
    "\n",
    "        print >> outfile, header\n",
    "        print >> outfile, res\n",
    "\n",
    "    print \"\\n=== GNAVIGATOR GENETIC MAP RESULTS ===\"\n",
    "    print \"%s (%s%%) scaffolds had 2+ complete cDNAs from the genetic map aligned to them.\" % (num_scaff_checked, pct_LGscaff)\n",
    "    print \"%s (%s%%) case(s) were from the same linkage group and in the expected order.\" % (num_goodLG, pct_goodLG)\n",
    "    print \"%s (%s%%) case(s) were from the same linkage group, but NOT in the expected order.\" % (num_WO_LG, pct_WO_LG)\n",
    "    print \"%s (%s%%) case(s) were from different linkage groups.\" % (num_diffLG, pct_diffLG)\n",
    "    print report_time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
