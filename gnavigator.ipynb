{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# purpose: create a tool similar to CEGMA/BUSCO that uses genetic map information to assess \n",
    "#    completeness and quality of an assembly and reporting a simple set of metrics\n",
    "\n",
    "# want to distinguish complete, partial, fragmented, duplicated, poorly mapped, and missing\n",
    "# complete: 90% of sequence is aligned with 95% identity\n",
    "# partial: less than 90% of sequence is aligned to a single scaffold, other 10% unaligned\n",
    "# fragmented: 90% of a sequence is aligned, but over multiple scaffolds\n",
    "## would need to use check_aln in 'report' mode and assess separately\n",
    "## alignment would be reported in \"*.transloc\"\n",
    "# duplicated: as complete, but at multiple locations\n",
    "## alignment would be reported in \"*.mult\"\n",
    "# poorly mapped: as complete, partial, or fragmented, but with less than 90% identity\n",
    "# missing: not aligned by gmap\n",
    "## assessed separately\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import argparse\n",
    "from itertools import groupby\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "# return the sequence from the assembly that corresponds to the cDNA\n",
    "# report if any genetic map cDNAs should be found between cDNAs that are observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_aln(aln, mode):\n",
    "    \"\"\"check the alignment of a gcat map sequence\"\"\"\n",
    "\n",
    "    matches = float(aln.matches)\n",
    "    mismatches = float(aln.mismatches)\n",
    "    qinserts = float(aln.qbaseinsert)\n",
    "    qsize = float(aln.qsize)\n",
    "    qstart = float(aln.qstart)\n",
    "    qend = float(aln.qend)\n",
    "    scaf = aln.tname\n",
    "    cDNA = aln.qname\n",
    "    \n",
    "    seg = qend - qstart\n",
    "    pid = matches / seg\n",
    "    # want to penalize insertions b/c reflects correctness of assembly\n",
    "    pcov = (matches + mismatches - qinserts) / qsize\n",
    "    \n",
    "    if mode == 'assess':\n",
    "        if pid >= 0.95 and pcov >= 0.95:\n",
    "            return (cDNA, scaf, 'Complete')\n",
    "        elif pid >= 0.95 and pcov < 0.95:\n",
    "            if pcov >= 0.5:\n",
    "                return (cDNA, scaf, 'Partial')\n",
    "            else:\n",
    "                return (cDNA, scaf, 'Poorly mapped')\n",
    "        else:\n",
    "            return (cDNA, scaf, 'Poorly mapped')\n",
    "    \n",
    "    elif mode == 'report':\n",
    "        goodb = matches\n",
    "        # want to penalize insertions b/c reflects correctness of assembly\n",
    "        covb = matches + mismatches - qinserts\n",
    "        \n",
    "    return (goodb, covb, seg, qsize, cDNA, scaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_frag(alns):\n",
    "    \"\"\"check if 'chimeric' alignment is good or not\"\"\"\n",
    "    # take in a series of blat alignments and evaluate them together\n",
    "    # TODO extend to assess non-chimeric alignments\n",
    "    ## some cDNAs may be fragmented along >2 scaffolds, with some missing bits in the middle\n",
    "    goodb = 0\n",
    "    covb = 0\n",
    "    seg = 0\n",
    "    qsize = 0\n",
    "    cDNA = ''\n",
    "    scaf = []\n",
    "        \n",
    "    for aln in alns:\n",
    "        this_aln = check_aln(aln, 'report')\n",
    "        goodb += this_aln[0]\n",
    "        covb += this_aln[1]\n",
    "        seg += this_aln[2]\n",
    "        scaf.append(this_aln[5])\n",
    "    else:\n",
    "        qsize = this_aln[3]\n",
    "        cDNA = this_aln[4]\n",
    "    \n",
    "    pid = goodb / seg\n",
    "    pcov = covb / qsize\n",
    "    \n",
    "    scaf_rep = \";\".join(scaf)\n",
    "    if pid >= 0.95 and pcov >= 0.95:\n",
    "        return (cDNA, scaf_rep, 'Fragmented')\n",
    "    elif pid >= 0.95 and pcov < 0.95:\n",
    "        if pcov > 0.5:\n",
    "            return (cDNA, scaf_rep, 'Partial') # distinguish from partials in a single piece?\n",
    "        else:\n",
    "            return (cDNA, scaf_rep, 'Poorly mapped')\n",
    "    else:\n",
    "        return (cDNA, scaf_rep, 'Poorly mapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dupl(alns):\n",
    "    \"\"\"check if a gcat sequence should be considered duplicated or not based on its multiple alignments\"\"\"\n",
    "    # more than one alignment must be considered complete in order to be duplicated\n",
    "    # one or more partial, fragmented, poorly mapped will not count\n",
    "    cDNA = ''\n",
    "    scaf = []\n",
    "    results = {'Complete':[], 'Partial':[], 'Duplicated':[], 'Poorly mapped':[]}\n",
    "    for aln in alns:\n",
    "        this_aln = check_aln(aln, 'assess')\n",
    "        res = this_aln[-1]\n",
    "        results[res].append(this_aln)\n",
    "        scaf.append(this_aln[1])\n",
    "    else:\n",
    "        cDNA = this_aln[0]\n",
    "\n",
    "    scaf_rep = \";\".join(scaf)\n",
    "    num_complete = len(results['Complete'])\n",
    "    if num_complete == 1:\n",
    "        best_scaf = scaf[0]\n",
    "        return (cDNA, best_scaf, 'Complete')\n",
    "    elif num_complete > 1:\n",
    "        return (cDNA, scaf_rep, 'Duplicated')\n",
    "    else:\n",
    "        if len(results['Partial']) >= 1:\n",
    "            return (cDNA, scaf_rep, 'Partial')\n",
    "        else:\n",
    "            return (cDNA, scaf_rep, 'Poorly mapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_aligned(uniqA, duplA, tlocA):\n",
    "    \"\"\"count how many seqs have any alignment whatsoever\"\"\"\n",
    "    aligned = set()\n",
    "    for rec in uniqA.qname.unique():\n",
    "        aligned.add(rec)\n",
    "    for rec in duplA.qname.unique():\n",
    "        aligned.add(rec)\n",
    "    for rec in tlocA.qname.unique():\n",
    "        aligned.add(rec)\n",
    "        \n",
    "    return len(aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_LG(query, genetic_map):\n",
    "    \"\"\"check if cDNAs are from the same LG\"\"\"\n",
    "    # query is a pandas array of a single scaffold's alignments\n",
    "    # genetic_map is a pandas array of LG\\tcM\\tcDNA\n",
    "    # assume for now that cDNA is in genetic_map$cDNA\n",
    "    # returns 'same LG, right order', 'same LG, wrong order', or 'different LG'\n",
    "    refs = query.qname.tolist()\n",
    "    thisMap = genetic_map[genetic_map.cDNA.isin(refs)]\n",
    "    numLG = len(thisMap.LG.unique())\n",
    "    if len(thisMap) == 2:\n",
    "        if numLG == 1:\n",
    "            return 'Same LG, right order'\n",
    "        else:\n",
    "            return 'Different LG'\n",
    "    else:\n",
    "        if numLG == 1:\n",
    "            # comparing two lists of the same length will return True if order is the same\n",
    "            # compare both forward and reverse orders\n",
    "            fwdA = query.sort_values(['tstart'])\n",
    "            fwdL = fwdA.qname.tolist()\n",
    "            revA = query.sort_values(['tstart'], ascending=False)\n",
    "            revL = revA.qname.tolist()\n",
    "            mapL = thisMap.cDNA.tolist()\n",
    "            if mapL == fwdL:\n",
    "                return 'same LG, right order'\n",
    "            elif mapL == revL:\n",
    "                return 'Same LG, right order'\n",
    "            else:\n",
    "                return 'Same LG, wrong order'\n",
    "        else:\n",
    "            return 'Different LG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jira_formatter(num_pct_tuple):\n",
    "    # num_pct_tuple is tuple of (num, pct)\n",
    "    num = num_pct_tuple[0]\n",
    "    pct = num_pct_tuple[1]\n",
    "    outbuff = str(num) + \" \" + \"(\" + str(pct) + \"%)\"\n",
    "    return outbuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_formatter(results_tuple):\n",
    "    # results_tuple is from one of the check* functions\n",
    "    # (cDNA, scaffold, status), or (cDNA, scaffold1;scaffold2..., status)\n",
    "    nam = results_tuple[0]\n",
    "    scaf = results_tuple[1].split(\";\")\n",
    "    stat = results_tuple[2]\n",
    "    \n",
    "    for entry in scaf:\n",
    "        outbuff = \"\\t\".join([nam, stat, entry])\n",
    "        yield outbuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fasta_iter\n",
    "#\n",
    "#   modified from code written by brentp and retrieved from https://www.biostars.org/p/710/ on May 5, 2015\n",
    "#   given a fasta file. yield tuples of header, sequence\n",
    "def fasta_iter(fasta_name):\n",
    "    # ditch the boolean (x[0]) and just keep the header or sequence since\n",
    "    # we know they alternate.\n",
    "    faiter = (x[1] for x in groupby(fasta_name, lambda line: line[0] == \">\"))\n",
    "    for header in faiter:\n",
    "        # drop the \">\"\n",
    "        header = header.next()[1:].strip()\n",
    "        # join all sequence lines to one.\n",
    "        seq = \"\".join(s.strip() for s in faiter.next())\n",
    "        yield header, seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing(fasta, res_dict):\n",
    "    # fasta is cDNA fasta\n",
    "    # res_dict is results dictionary like cDNA_res\n",
    "    cDNA_set = set()\n",
    "    with open(fasta, 'r') as infile:\n",
    "        for rec in fasta_iter(infile):\n",
    "            seqid = rec[0]\n",
    "            seqid_only = seqid.split(\" \")[0]\n",
    "            cDNA_set.add(seqid_only)\n",
    "    tot_cDNA = len(cDNA_set)\n",
    "\n",
    "    detected = set()\n",
    "    for key, value in res_dict.items():\n",
    "        resID = set([x[0] for x in value])\n",
    "        detected = detected.union(resID)\n",
    "\n",
    "    missing = cDNA_set.difference(detected)\n",
    "    missingL = [(x, 'NA', 'Missing') for x in missing]\n",
    "    \n",
    "    return (missingL, tot_cDNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parser\n",
    "parser = argparse.ArgumentParser(description='Assess assembly quality and completeness using cDNA sequences')\n",
    "parser.add_argument('cDNA', help='FASTA file of cDNA sequences to align to assembly') # cDNA sequence fasta\n",
    "parser.add_argument('genome', help='FASTA file of genome assembly to assess')\n",
    "parser.add_argument('-p', '--prefix', help='Prefix to use for intermediate and output files [gnavigator]', default='gnavigator') # prefix\n",
    "parser.add_argument('-d', '--db_dir', help='Path to directory containing prebuilt GMAP index [optional]') # gmap db dir\n",
    "parser.add_argument('-n', '--db_name', help='Name of prebuilt GMAP index [optional]') # gmap db name\n",
    "parser.add_argument('-t', '--threads', help='Number of threads for GMAP alignment [1]', action='store', default='1')\n",
    "parser.add_argument('-m', '--genetic_map', help='Genetic map file as tsv with LG:cDNA pairs [optional]')\n",
    "parser.add_argument('-a', '--trim_accessions', help='Trim GenBank-style revision code from sequence IDs', action='store_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process args\n",
    "args = parser.parse_args()\n",
    "cDNA = args.cDNA\n",
    "genome = args.genome\n",
    "prefix = args.prefix\n",
    "threads = args.threads\n",
    "\n",
    "if args.db_dir:\n",
    "    dbDir = args.db_dir\n",
    "else:\n",
    "    dbDir = ''.join([os.getcwd(), '/', prefix, '-gmap-index-dir'])\n",
    "if args.db_name:\n",
    "    dbName = args.db_name\n",
    "else:\n",
    "    dbName = '-'.join([prefix, 'gmap-index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path to this script, and assume that the gmap sh scripts are there too\n",
    "gnavigator_path = re.sub('gnavigator.py', '', os.path.realpath(__file__))\n",
    "\n",
    "# check if alignments have already been done\n",
    "checkU = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".uniq\"]))\n",
    "checkM = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".mult\"]))\n",
    "checkD = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".transloc\"]))\n",
    "if checkU and checkM and checkD:\n",
    "    print \"\\n=== Skipping GMAP alignment stage ===\"\n",
    "    print \"Gnavigator found pre-existing GMAP alignment results. Will use the following files:\"\n",
    "    print ''.join([os.getcwd(), '/', prefix, \".uniq\"])\n",
    "    print ''.join([os.getcwd(), '/', prefix, \".mult\"])\n",
    "    print ''.join([os.getcwd(), '/', prefix, \".transloc\"])\n",
    "\n",
    "# make gmap index if not supplied by user\n",
    "else:\n",
    "    if not args.db_dir and not args.db_name:\n",
    "        print \"\\n ===Building GMAP database=== \"\n",
    "        try:\n",
    "            subprocess.call([gnavigator_path + '/build-index.sh', dbDir, dbName, genome])\n",
    "        except:\n",
    "            print 'Failed to build GMAP index.'\n",
    "            print 'Make sure that build-index.sh is in the same directory as gnavigator.'\n",
    "            sys.exit(1)\n",
    "\n",
    "# run gmap alignment\n",
    "    print \"\\n=== Performing GMAP alignments ===\"\n",
    "    try:\n",
    "        subprocess.call([gnavigator_path + '/run-gmap.sh', dbDir, dbName, threads, prefix, cDNA])\n",
    "    except:\n",
    "        print 'Failed to perform GMAP alignment.'\n",
    "        print 'Make sure that run-gmap.sh is in the same directory as gnavigator.'\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prefix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-99ec9a7528e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m              'blockcount', 'blocksizes', 'qstarts', 'tstarts']\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0muniqDat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'uniq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mduplDat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mult'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtlocDat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transloc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prefix' is not defined"
     ]
    }
   ],
   "source": [
    "# read in the data and define extent\n",
    "col_names = ['matches', 'mismatches', 'repmatches', 'ncount', 'qnuminsert', 'qbaseinsert', 'tnuminsert', \n",
    "             'tbaseinsert', 'strand', 'qname', 'qsize', 'qstart', 'qend', 'tname', 'tsize', 'tstart', 'tend',\n",
    "             'blockcount', 'blocksizes', 'qstarts', 'tstarts']\n",
    "\n",
    "uniqDat = pd.read_csv('.'.join([prefix, 'uniq']), sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "duplDat = pd.read_csv('.'.join([prefix, 'mult']), sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "tlocDat = pd.read_csv('.'.join([prefix, 'transloc']), sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "\n",
    "# remove the \".1\" etc. added by GenBank to the query names?\n",
    "if args.trim_accessions:\n",
    "    uniqDat['qname'] = uniqDat['qname'].str[:-2]\n",
    "    duplDat['qname'] = duplDat['qname'].str[:-2]\n",
    "    tlocDat['qname'] = tlocDat['qname'].str[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR DEV ###\n",
    "# read in the data and define extent\n",
    "col_names = ['matches', 'mismatches', 'repmatches', 'ncount', 'qnuminsert', 'qbaseinsert', 'tnuminsert', \n",
    "             'tbaseinsert', 'strand', 'qname', 'qsize', 'qstart', 'qend', 'tname', 'tsize', 'tstart', 'tend',\n",
    "             'blockcount', 'blocksizes', 'qstarts', 'tstarts']\n",
    "\n",
    "uniqDat = pd.read_csv('runs/sitka-new-strategy-postLINKS-95.uniq', sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "duplDat = pd.read_csv('runs/sitka-new-strategy-postLINKS-95.mult', sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "tlocDat = pd.read_csv('runs/sitka-new-strategy-postLINKS-95.transloc', sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "\n",
    "# remove the \".1\" etc. added by GenBank to the query names?\n",
    "#if args.trim_accessions:\n",
    "#    uniqDat['qname'] = uniqDat['qname'].str[:-2]\n",
    "#    duplDat['qname'] = duplDat['qname'].str[:-2]\n",
    "#    tlocDat['qname'] = tlocDat['qname'].str[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in genetic map, if supplied\n",
    "# format for spruce map is LG\\tcM\\tcDNA\n",
    "if args.genetic_map:\n",
    "    mapDat = pd.read_csv(arg.genetic_map, sep=\"\\t\", comment='#', low_memory=False, header=None, names=['LG', 'cM', 'cDNA'])\n",
    "    # limit genetic map analysis to complete (i.e. single) cDNAs to improve confidence\n",
    "    map_cDNA = set(mapDat.cDNA.tolist())\n",
    "    uniqDatMap = uniqDat[uniqDat.qname.isin(map_cDNA)]\n",
    "    uMap = uniqDatMap[uniqDatMap.tname.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup counters\n",
    "cDNA_res = {'Complete':[], 'Duplicated':[], 'Partial':[], 'Fragmented':[], 'Poorly mapped':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply check_complete to whole set\n",
    "for rec in uniqDat.itertuples():\n",
    "    res = check_aln(rec, 'assess')\n",
    "    cDNA_res[res[2]].append(res) # append results tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply check_frag to whole set\n",
    "for qry in tlocDat.qname.unique():\n",
    "    this_qry = tlocDat[tlocDat.qname == qry]\n",
    "    frags = []\n",
    "    for rec in this_qry.itertuples():\n",
    "        frags.append(rec)\n",
    "    \n",
    "    res = check_frag(frags)\n",
    "    cDNA_res[res[2]].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply check_dupl to whole set\n",
    "for qry in duplDat.qname.unique():\n",
    "    this_qry = duplDat[duplDat.qname == qry]\n",
    "    frags = []\n",
    "    for rec in this_qry.itertuples():\n",
    "        frags.append(rec)\n",
    "    \n",
    "    res = check_dupl(frags)\n",
    "    cDNA_res[res[2]].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fragmented\n",
      "[('GQ0011_A02', 'scaffold614315,8199,f613956Z8199;scaffold115689,27569,f232224Z27569', 'Fragmented'), ('GQ0011_A15', 'scaffold1591329,2147,f1619251Z2147;scaffold7735429,464,f7765775Z464', 'Fragmented'), ('GQ0011_C07', 'scaffold300674,15581,f287782Z15581;scaffold1427522,2590,f1453723Z2590', 'Fragmented')]\n",
      "[('WS0348_I08', 'scaffold167422,22719,f155389Z22719;scaffold240230,18223,f227085Z18223', 'Fragmented'), ('WS0349_A03', 'scaffold20255948,278,f20280386Z278;scaffold156564,23579,f144862Z23579', 'Fragmented'), ('WS0349_K23', 'scaffold2841561,868,f2874501Z868;scaffold1027366,4296,f1045382Z4296', 'Fragmented')]\n",
      "Poorly mapped\n",
      "[('GQ0011_D15', 'scaffold257688,17376,f244572Z17376', 'Poorly mapped'), ('GQ0012_G11', 'scaffold137336,25262,f126336Z25262', 'Poorly mapped'), ('GQ0013_B18', 'scaffold683926,7247,f688736Z7247', 'Poorly mapped')]\n",
      "[('WS0348_J22', 'scaffold414695,12042,f661042Z12042;scaffold25822,60421,f470346z10580k10a0m-804_f104505Z49841', 'Poorly mapped'), ('WS0349_L04', 'scaffold16821,56877,f113150Z56877;scaffold3198452,808,f3234286Z808;scaffold775492,6230,f785287Z6230;scaffold2413958,956,f2449529Z956', 'Poorly mapped'), ('WS0349_O04', 'scaffold193588,20885,f180979Z20885;scaffold320675,14844,f307988Z14844;scaffold29734,47593,f25780Z47593', 'Poorly mapped')]\n",
      "Partial\n",
      "[('GQ0011_D17', 'scaffold6072174,540,f6115707Z540', 'Partial'), ('GQ0013_M12', 'scaffold186527,23529,f1605813z2179k96a0m-227_f196289Z21350', 'Partial'), ('GQ0015_M24', 'scaffold151129,24023,f139619Z24023', 'Partial')]\n",
      "[('WS0347_K06', 'scaffold15825,57893,f13387Z57893;scaffold907130,5093,f921844Z5093;scaffold559805,9062,f555790Z9062;scaffold155049,23705,f143405Z23705', 'Partial'), ('WS0348_L16', 'scaffold3415226,776,f3446071Z776;scaffold6200414,533,f6229729Z533;scaffold5254092,592,f5287338Z592;scaffold715669,6869,f722382Z6869;scaffold1402740,2668,f1428424Z2668;scaffold447217,11266,f437711Z11266;scaffold644959,14462,f646872Z7761k12a0m-766_r738085z6701;scaffold5085261,605,f5115521Z605;scaffold3820821,723,f3857545Z723;scaffold6982678,495,f7009906Z495', 'Partial'), ('WS0349_F08', 'scaffold412991,12086,f402378Z12086;scaffold2235764,1005,f2268182Z1005;scaffold2169886,1089,f2202670Z1089;scaffold1357724,2817,f1382625Z2817', 'Partial')]\n",
      "Complete\n",
      "[('GQ0011_A20', 'scaffold380298,12964,f368747Z12964', 'Complete'), ('GQ0011_A21', 'scaffold92862,30623,f84051Z30623', 'Complete'), ('GQ0011_B07', 'scaffold23844,51116,f20500Z51116', 'Complete')]\n",
      "[('WS0348_J23', 'scaffold663067,7517,f666321Z7517', 'Complete'), ('WS0348_O05', 'scaffold87965,31367,f101225Z31367', 'Complete'), ('WS0349_P18', 'scaffold34734,45166,f30292Z45166', 'Complete')]\n",
      "Duplicated\n",
      "[('GQ0011_B21', 'scaffold171265,22430,f159095Z22430;scaffold1509417,2353,f1536593Z2353', 'Duplicated'), ('GQ0011_G15', 'scaffold74198,33779,f66548Z33779;scaffold269554,16844,f256515Z16844;scaffold403632,12328,f392737Z12328;scaffold955020,4750,f971051Z4750', 'Duplicated'), ('GQ0011_I04', 'scaffold128389,31107,r941620z4952k19a0m-927_f117817Z26155;scaffold1397349,2685,f1422899Z2685', 'Duplicated')]\n",
      "[('WS0349_E22', 'scaffold6867353,500,f6900581Z500;scaffold10582354,384,f10612485Z384;scaffold6639350,510,f6682691Z510;scaffold1630923,2055,f1659718Z2055', 'Duplicated'), ('WS0349_J23', 'scaffold10557,64694,f47949Z64694;scaffold254546,17527,f241384Z17527;scaffold710594,6929,f716960Z6929', 'Duplicated'), ('WS0349_N19', 'scaffold203354,20265,f190579Z20265;scaffold1251525,3209,f1274475Z3209;scaffold11566434,364,f11635163Z364;scaffold12614463,345,f12655572Z345;scaffold8179913,448,f8217498Z448;scaffold9478295,410,f9521529Z410;scaffold12565581,346,f12626359Z346;scaffold8344514,443,f8365719Z443;scaffold4954687,615,f4993244Z615;scaffold19100435,287,f18333706Z287', 'Duplicated')]\n"
     ]
    }
   ],
   "source": [
    "### for dev\n",
    "\n",
    "for i in cDNA_res:\n",
    "    print i\n",
    "    print cDNA_res[i][:3]\n",
    "    print cDNA_res[i][-3:]\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total number of query sequences\n",
    "check_missing = find_missing(cDNA, cDNA_res)\n",
    "TOT = check_missing[1]\n",
    "cDNA_res['Missing'] = check_missing[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GNAVIGATOR RESULTS ===\n",
      "9972 (36.74%) complete sequences\n",
      "2347 (8.65%) duplicated sequences\n",
      "4150 (15.29%) fragmented sequences\n",
      "3879 (14.29%) partial sequences\n",
      "5417 (19.96%) poorly mapped sequences\n",
      "1378 (5.08%) missing sequences\n",
      "27143 (100.0%) sequences were evaluated\n"
     ]
    }
   ],
   "source": [
    "# calc percentages and report results\n",
    "num_complete = len(cDNA_res['Complete'])\n",
    "num_duplicated = len(cDNA_res['Duplicated'])\n",
    "num_partial = len(cDNA_res['Partial'])\n",
    "num_fragmented = len(cDNA_res['Fragmented'])\n",
    "num_poor = len(cDNA_res['Poorly mapped'])\n",
    "num_missing = len(cDNA_res['Missing'])\n",
    "\n",
    "rate_complete = float(num_complete) / float(TOT)\n",
    "rate_duplicated = float(num_duplicated) / float(TOT)\n",
    "rate_partial = float(num_partial) / float(TOT)\n",
    "rate_fragmented = float(num_fragmented) / float(TOT)\n",
    "rate_poor = float(num_poor) / float(TOT)\n",
    "rate_missing = float(num_missing) / float(TOT)\n",
    "\n",
    "pct_complete = round(100.0 * rate_complete, 2)\n",
    "pct_duplicated = round(100.0 * rate_duplicated, 2)\n",
    "pct_partial = round(100.0 * rate_partial, 2)\n",
    "pct_fragmented = round(100 * rate_fragmented, 2)\n",
    "pct_poor = round(100 * rate_poor, 2)\n",
    "pct_missing = round(100 * rate_missing, 2)\n",
    "\n",
    "# count how many sequences are missing alignments\n",
    "#obs = count_aligned(uniqDat, duplDat, tlocDat)\n",
    "#num_miss = TOT - obs\n",
    "#rate_miss = float(num_miss) / float(TOT)\n",
    "#pct_miss = round(100.0 * rate_miss, 2)\n",
    "\n",
    "# report if the right number of sequences have a result\n",
    "num_counted = sum([num_complete, num_duplicated, num_fragmented, num_partial, num_poor, num_missing])\n",
    "rate_counted = float(num_counted) / float(TOT)\n",
    "pct_counted = round(100 * rate_counted, 2)\n",
    "\n",
    "# write to tsv\n",
    "tsvout = \"-\".join([prefix, \"results.tsv\"])\n",
    "with open(tsvout, \"w\") as outfile:\n",
    "    header = \"\\t\".join([\"\", \"Complete\", \"Duplicated\", \"Fragmented\", \"Partial\", \"Poorly Mapped\", \"Missing\", \"Total cDNAs searched\"])\n",
    "    nums = \"\\t\".join([str(x) for x in [\"Number\", num_complete, num_duplicated, num_fragmented, num_partial, num_poor, num_missing, num_counted]])\n",
    "    pcts = \"\\t\".join([str(x) for x in [\"Percent\", pct_complete, pct_duplicated, pct_fragmented, pct_partial, pct_poor, pct_missing, pct_counted]])\n",
    "\n",
    "    print >> outfile, header\n",
    "    print >> outfile, nums\n",
    "    print >> outfile, pcts\n",
    "\n",
    "jiraout = \"-\".join([prefix, \"results.jira\"])\n",
    "with open(jiraout, \"w\") as outfile:\n",
    "    header = \"||\".join([\"\", \"Complete\", \"Duplicated\", \"Fragmented\", \"Partial\", \"Poorly Mapped\", \"Missing\", \"Total cDNAs searched\", \"\"])\n",
    "    nums = [num_complete, num_duplicated, num_fragmented, num_partial, num_poor, num_missing, num_counted]\n",
    "    pcts = [pct_complete, pct_duplicated, pct_fragmented, pct_partial, pct_poor, pct_missing, pct_counted]\n",
    "    res = \"|\" + \"|\".join([jira_formatter(x) for x in zip(nums, pcts)]) + \"|\"\n",
    "    \n",
    "    print >> outfile, header\n",
    "    print >> outfile, res\n",
    "\n",
    "# print to STDOUT\n",
    "print \"\\n=== GNAVIGATOR RESULTS ===\"\n",
    "print \"%s (%s%%) complete sequences\" % (num_complete, pct_complete)\n",
    "print \"%s (%s%%) duplicated sequences\" % (num_duplicated, pct_duplicated)\n",
    "print \"%s (%s%%) fragmented sequences\" % (num_fragmented, pct_fragmented)\n",
    "print \"%s (%s%%) partial sequences\" % (num_partial, pct_partial)\n",
    "print \"%s (%s%%) poorly mapped sequences\" % (num_poor, pct_poor)\n",
    "print \"%s (%s%%) missing sequences\" % (num_missing, pct_missing)\n",
    "print \"%s (%s%%) sequences were evaluated\" % (num_counted, pct_counted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out cDNA:scaffold mappings\n",
    "header = \"\\t\".join([\"# cDNA ID\", \"Status\", \"Scaffold\"])\n",
    "full_out = \"-\".join([prefix, \"full-cDNA-results-table.tsv\"])\n",
    "with open(full_out, \"w\") as outfile:\n",
    "    print >> outfile, header\n",
    "    for status, result in cDNA_res.items():\n",
    "        for res in result:\n",
    "            for t in table_formatter(res):\n",
    "                print >> outfile, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All scaffolds to be checked against genetic map were successfully checked\n",
      "76\n",
      "1\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# apply check_LG to whole uniq set\n",
    "if args.genetic_map:\n",
    "    num_goodLG = 0 # same LG, right order\n",
    "    num_WO_LG = 0 # same LG, wrong order\n",
    "    num_diffLG = 0 # different LG\n",
    "\n",
    "    for rec in uMap.tname.unique():\n",
    "        thisScaf = uMap[uMap.tname.isin([rec])]\n",
    "        res = check_LG(thisScaf, mapDat)\n",
    "        if res == 'Same LG, right order':\n",
    "            num_goodLG += 1\n",
    "        elif res == 'Same LG, wrong order':\n",
    "            num_WO_LG += 1\n",
    "        elif res == 'Different LG':\n",
    "            num_diffLG += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GENETIC MAP GNAVIGATOR RESULTS ===\n",
      "83 (0.31%) scaffolds had 2+ complete cDNAs from the genetic map aligned to them.\n",
      "76 (91.57%) case(s) were from the same linkage group and in the expected order.\n",
      "1 (1.2%) case(s) were from the same linkage group, but NOT in the expected order.\n",
      "6 (7.23%) case(s) were from different linkage groups.\n"
     ]
    }
   ],
   "source": [
    "# report genetic map results\n",
    "if args.genetic_map:\n",
    "    num_scaff_toCheck = len(uMap.tname.unique())\n",
    "    num_scaff_checked = num_goodLG + num_WO_LG + num_diffLG\n",
    "    if num_scaff_toCheck == num_scaff_checked:\n",
    "        rate_LGscaff = float(num_scaff_checked) / float(TOT)\n",
    "        rate_goodLG = float(num_goodLG) / float(num_scaff_checked)\n",
    "        rate_WO_LG = float(num_WO_LG) / float(num_scaff_checked)\n",
    "        rate_diffLG = float(num_diffLG) / float(num_scaff_checked)\n",
    "\n",
    "        pct_LGscaff = round(100.0 * rate_LGscaff, 2) \n",
    "        pct_goodLG = round(100.0 * rate_goodLG, 2)\n",
    "        pct_WO_LG = round(100.0 * rate_WO_LG, 2)\n",
    "        pct_diffLG = round(100.0 * rate_diffLG, 2)\n",
    "\n",
    "    else:\n",
    "        print 'Not all scaffolds to be checked against genetic map were successfully checked.'\n",
    "        print 'Maybe something is wrong with the input data?'\n",
    "        sys.exit(2)\n",
    "    \n",
    "    # write to tsv\n",
    "    tsvout = \"-\".join([prefix, \"genetic-map-results.tsv\"])\n",
    "    with open(tsvout, \"w\") as outfile:\n",
    "        header = \"\\t\".join([\"\", \"Same LG, right order\", \"Same LG, wrong order\", \"Different LG\", \"Total scaffolds analyzed\"])\n",
    "        nums = \"\\t\".join([str(x) for x in [\"Number\", num_goodLG, num_WO_LG, num_diffLG, num_scaff_checked]])\n",
    "        pcts = \"\\t\".join([str(x) for x in [\"Percent\", pct_goodLG, pct_WO_LG, pct_diffLG, pct_LGscaff]])\n",
    "\n",
    "        print >> outfile, header\n",
    "        print >> outfile, nums\n",
    "        print >> outfile, pcts\n",
    "\n",
    "    jiraout = \"-\".join([prefix, \"genetic-map-results.jira\"])\n",
    "    with open(jiraout, \"w\") as outfile:\n",
    "        header = \"||\".join([\"\", \"Same LG, right order\", \"Same LG, wrong order\", \"Different LG\", \"Total scaffolds analyzed\", \"\"])\n",
    "        nums = [num_goodLG, num_WO_LG, num_diffLG, num_scaff_checked]\n",
    "        pcts = [pct_goodLG, pct_WO_LG, pct_diffLG, pct_LGscaff]\n",
    "        res = \"|\" + \"|\".join([jira_formatter(x) for x in zip(nums, pcts)]) + \"|\"\n",
    "\n",
    "        print >> outfile, header\n",
    "        print >> outfile, res\n",
    "\n",
    "    print \"\\n=== GENETIC MAP GNAVIGATOR RESULTS ===\"\n",
    "    print \"%s (%s%%) scaffolds had 2+ complete cDNAs from the genetic map aligned to them.\" % (num_scaff_checked, pct_LGscaff)\n",
    "    print \"%s (%s%%) case(s) were from the same linkage group and in the expected order.\" % (num_goodLG, pct_goodLG)\n",
    "    print \"%s (%s%%) case(s) were from the same linkage group, but NOT in the expected order.\" % (num_WO_LG, pct_WO_LG)\n",
    "    print \"%s (%s%%) case(s) were from different linkage groups.\" % (num_diffLG, pct_diffLG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
