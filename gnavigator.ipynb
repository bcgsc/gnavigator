{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# purpose: create a tool similar to CEGMA/BUSCO that uses genetic map information to assess \n",
    "#    completeness and quality of an assembly and reporting a simple set of metrics\n",
    "\n",
    "# want to distinguish complete, partial, fragmented, duplicated, poorly mapped, and missing\n",
    "# complete: 90% of sequence is aligned with 95% identity\n",
    "# partial: less than 90% of sequence is aligned to a single scaffold, other 10% unaligned\n",
    "# fragmented: 90% of a sequence is aligned, but over multiple scaffolds\n",
    "## would need to use check_aln in 'report' mode and assess separately\n",
    "## alignment would be reported in \"*.transloc\"\n",
    "# duplicated: as complete, but at multiple locations\n",
    "## alignment would be reported in \"*.mult\"\n",
    "# poorly mapped: as complete, partial, or fragmented, but with less than 90% identity\n",
    "# missing: not aligned by gmap\n",
    "## assessed separately\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import argparse\n",
    "from itertools import groupby\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    print 'ERROR: The pandas module is required, but was not found. Please install and try again.'\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "# return the sequence from the assembly that corresponds to the cDNA\n",
    "# report if any genetic map cDNAs should be found between cDNAs that are observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_aln(aln, mode):\n",
    "    \"\"\"check the alignment of a gcat map sequence\"\"\"\n",
    "\n",
    "    matches = float(aln.matches)\n",
    "    mismatches = float(aln.mismatches)\n",
    "    qinserts = float(aln.qbaseinsert)\n",
    "    qsize = float(aln.qsize)\n",
    "    qstart = float(aln.qstart)\n",
    "    qend = float(aln.qend)\n",
    "    scaf = aln.tname\n",
    "    cDNA = aln.qname\n",
    "    \n",
    "    seg = qend - qstart\n",
    "    pid = matches / seg\n",
    "    # want to penalize insertions b/c reflects correctness of assembly\n",
    "    pcov = (matches + mismatches - qinserts) / qsize\n",
    "    \n",
    "    if mode == 'assess':\n",
    "        if pid >= 0.95 and pcov >= 0.95:\n",
    "            return (cDNA, scaf, 'Complete')\n",
    "        elif pid >= 0.95 and pcov < 0.95:\n",
    "            if pcov >= 0.5:\n",
    "                return (cDNA, scaf, 'Partial')\n",
    "            else:\n",
    "                return (cDNA, scaf, 'Poorly mapped')\n",
    "        else:\n",
    "            return (cDNA, scaf, 'Poorly mapped')\n",
    "    \n",
    "    elif mode == 'report':\n",
    "        goodb = matches\n",
    "        # want to penalize insertions b/c reflects correctness of assembly\n",
    "        covb = matches + mismatches - qinserts\n",
    "        \n",
    "    return (goodb, covb, seg, qsize, cDNA, scaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_frag(alns):\n",
    "    \"\"\"check if 'chimeric' alignment is good or not\"\"\"\n",
    "    # take in a series of blat alignments and evaluate them together\n",
    "    # TODO extend to assess non-chimeric alignments\n",
    "    ## some cDNAs may be fragmented along >2 scaffolds, with some missing bits in the middle\n",
    "    goodb = 0\n",
    "    covb = 0\n",
    "    seg = 0\n",
    "    qsize = 0\n",
    "    cDNA = ''\n",
    "    scaf = []\n",
    "        \n",
    "    for aln in alns:\n",
    "        this_aln = check_aln(aln, 'report')\n",
    "        goodb += this_aln[0]\n",
    "        covb += this_aln[1]\n",
    "        seg += this_aln[2]\n",
    "        scaf.append(this_aln[5])\n",
    "    else:\n",
    "        qsize = this_aln[3]\n",
    "        cDNA = this_aln[4]\n",
    "    \n",
    "    pid = goodb / seg\n",
    "    pcov = covb / qsize\n",
    "    \n",
    "    scaf_rep = \";\".join(scaf)\n",
    "    if pid >= 0.95 and pcov >= 0.95:\n",
    "        return (cDNA, scaf_rep, 'Fragmented')\n",
    "    elif pid >= 0.95 and pcov < 0.95:\n",
    "        if pcov > 0.5:\n",
    "            return (cDNA, scaf_rep, 'Partial') # distinguish from partials in a single piece?\n",
    "        else:\n",
    "            return (cDNA, scaf_rep, 'Poorly mapped')\n",
    "    else:\n",
    "        return (cDNA, scaf_rep, 'Poorly mapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dupl(alns):\n",
    "    \"\"\"check if a gcat sequence should be considered duplicated or not based on its multiple alignments\"\"\"\n",
    "    # more than one alignment must be considered complete in order to be duplicated\n",
    "    # one or more partial, fragmented, poorly mapped will not count\n",
    "    cDNA = ''\n",
    "    scaf = []\n",
    "    results = {'Complete':[], 'Partial':[], 'Duplicated':[], 'Poorly mapped':[]}\n",
    "    for aln in alns:\n",
    "        this_aln = check_aln(aln, 'assess')\n",
    "        res = this_aln[-1]\n",
    "        results[res].append(this_aln)\n",
    "        scaf.append(this_aln[1])\n",
    "    else:\n",
    "        cDNA = this_aln[0]\n",
    "\n",
    "    scaf_rep = \";\".join(scaf)\n",
    "    num_complete = len(results['Complete'])\n",
    "    if num_complete == 1:\n",
    "        best_scaf = scaf[0]\n",
    "        return (cDNA, best_scaf, 'Complete')\n",
    "    elif num_complete > 1:\n",
    "        return (cDNA, scaf_rep, 'Duplicated')\n",
    "    else:\n",
    "        if len(results['Partial']) >= 1:\n",
    "            return (cDNA, scaf_rep, 'Partial')\n",
    "        else:\n",
    "            return (cDNA, scaf_rep, 'Poorly mapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_aligned(uniqA, duplA, tlocA):\n",
    "    \"\"\"count how many seqs have any alignment whatsoever\"\"\"\n",
    "    aligned = set()\n",
    "    for rec in uniqA.qname.unique():\n",
    "        aligned.add(rec)\n",
    "    for rec in duplA.qname.unique():\n",
    "        aligned.add(rec)\n",
    "    for rec in tlocA.qname.unique():\n",
    "        aligned.add(rec)\n",
    "        \n",
    "    return len(aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_LG(query, genetic_map):\n",
    "    \"\"\"check if cDNAs are from the same LG\"\"\"\n",
    "    # query is a pandas array of a single scaffold's alignments\n",
    "    # genetic_map is a pandas array of LG\\tcM\\tcDNA\n",
    "    # assume for now that cDNA is in genetic_map$cDNA\n",
    "    # returns 'same LG, right order', 'same LG, wrong order', or 'different LG'\n",
    "    refs = query.qname.tolist()\n",
    "    thisMap = genetic_map[genetic_map.cDNA.isin(refs)]\n",
    "    numLG = len(thisMap.LG.unique())\n",
    "    if len(thisMap) == 2:\n",
    "        if numLG == 1:\n",
    "            return 'Same LG, right order'\n",
    "        else:\n",
    "            return 'Different LG'\n",
    "    else:\n",
    "        if numLG == 1:\n",
    "            # comparing two lists of the same length will return True if order is the same\n",
    "            # compare both forward and reverse orders\n",
    "            fwdA = query.sort_values(['tstart'])\n",
    "            fwdL = fwdA.qname.tolist()\n",
    "            revA = query.sort_values(['tstart'], ascending=False)\n",
    "            revL = revA.qname.tolist()\n",
    "            mapL = thisMap.cDNA.tolist()\n",
    "            if mapL == fwdL:\n",
    "                return 'Same LG, right order'\n",
    "            elif mapL == revL:\n",
    "                return 'Same LG, right order'\n",
    "            else:\n",
    "                return 'Same LG, wrong order'\n",
    "        else:\n",
    "            return 'Different LG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jira_formatter(num_pct_tuple):\n",
    "    # num_pct_tuple is tuple of (num, pct)\n",
    "    num = num_pct_tuple[0]\n",
    "    pct = num_pct_tuple[1]\n",
    "    outbuff = str(num) + \" \" + \"(\" + str(pct) + \"%)\"\n",
    "    return outbuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_formatter(results_tuple):\n",
    "    # results_tuple is from one of the check* functions\n",
    "    # (cDNA, scaffold, status), or (cDNA, scaffold1;scaffold2..., status)\n",
    "    nam = results_tuple[0]\n",
    "    scaf = results_tuple[1].split(\";\")\n",
    "    stat = results_tuple[2]\n",
    "    \n",
    "    for entry in scaf:\n",
    "        outbuff = \"\\t\".join([nam, stat, entry])\n",
    "        yield outbuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fasta_iter\n",
    "#\n",
    "#   modified from code written by brentp and retrieved from https://www.biostars.org/p/710/ on May 5, 2015\n",
    "#   given a fasta file. yield tuples of header, sequence\n",
    "def fasta_iter(fasta_name:\n",
    "    # ditch the boolean (x[0]) and just keep the header or sequence since\n",
    "    # we know they alternate.\n",
    "    # trim_flag corresponds to -a flag\n",
    "    ## will trim GenBank-style revision code from sequence IDs\n",
    "    faiter = (x[1] for x in groupby(fasta_name, lambda line: line[0] == \">\"))\n",
    "    for header in faiter:\n",
    "        # drop the \">\"\n",
    "        header = header.next()[1:].strip()\n",
    "        # join all sequence lines to one.\n",
    "        seq = \"\".join(s.strip() for s in faiter.next())\n",
    "        yield header, seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing(fasta, res_dict):\n",
    "    # fasta is cDNA fasta\n",
    "    # res_dict is results dictionary like cDNA_res\n",
    "    # trim_flag corresponds to -a flag, passed to fasta_iter\n",
    "    ## will trim GenBank-style revision code from sequence IDs\n",
    "    cDNA_set = set()\n",
    "    with open(fasta, 'r') as infile:\n",
    "        for rec in fasta_iter(infile):\n",
    "            seqid = rec[0]\n",
    "            seqid_only = seqid.split(\" \")[0]\n",
    "            cDNA_set.add(seqid_only)\n",
    "    tot_cDNA = len(cDNA_set)\n",
    "\n",
    "    detected = set()\n",
    "    for key, value in res_dict.items():\n",
    "        resID = set([x[0] for x in value])\n",
    "        detected = detected.union(resID)\n",
    "\n",
    "    missing = cDNA_set.difference(detected)\n",
    "    missingL = [(x, 'NA', 'Missing') for x in missing]\n",
    "    \n",
    "    return (missingL, tot_cDNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parser\n",
    "parser = argparse.ArgumentParser(description='Assess assembly quality and completeness using cDNA sequences')\n",
    "parser.add_argument('cDNA', help='FASTA file of cDNA sequences to align to assembly') # cDNA sequence fasta\n",
    "parser.add_argument('genome', help='FASTA file of genome assembly to assess')\n",
    "parser.add_argument('-p', '--prefix', help='Prefix to use for intermediate and output files [gnavigator]', default='gnavigator') # prefix\n",
    "parser.add_argument('-d', '--db_dir', help='Path to directory containing prebuilt GMAP index [optional]') # gmap db dir\n",
    "parser.add_argument('-n', '--db_name', help='Name of prebuilt GMAP index [optional]') # gmap db name\n",
    "parser.add_argument('-t', '--threads', help='Number of threads for GMAP alignment [1]', action='store', default='1')\n",
    "parser.add_argument('-m', '--genetic_map', help='Genetic map file as tsv with LG:cDNA pairs [optional]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process args\n",
    "args = parser.parse_args()\n",
    "cDNA = args.cDNA\n",
    "genome = args.genome\n",
    "prefix = args.prefix\n",
    "threads = args.threads\n",
    "\n",
    "if args.db_dir:\n",
    "    dbDir = args.db_dir\n",
    "else:\n",
    "    dbDir = ''.join([os.getcwd(), '/', prefix, '-gmap-index-dir'])\n",
    "if args.db_name:\n",
    "    dbName = args.db_name\n",
    "else:\n",
    "    dbName = '-'.join([prefix, 'gmap-index'])\n",
    "if args.genetic_map:\n",
    "    check_gm = True\n",
    "    gmfile = args.genetic_map\n",
    "else:\n",
    "    check_gm = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path to this script, and assume that the gmap sh scripts are there too\n",
    "gnavigator_path = re.sub('gnavigator.py', '', os.path.realpath(__file__))\n",
    "\n",
    "# check if alignments have already been done\n",
    "checkU = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".uniq\"]))\n",
    "checkM = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".mult\"]))\n",
    "checkD = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".transloc\"]))\n",
    "if checkU and checkM and checkD:\n",
    "    print \"\\n=== Skipping GMAP alignment stage ===\"\n",
    "    print \"Gnavigator found pre-existing GMAP alignment results. Will use the following files:\"\n",
    "    print ''.join([os.getcwd(), '/', prefix, \".uniq\"])\n",
    "    print ''.join([os.getcwd(), '/', prefix, \".mult\"])\n",
    "    print ''.join([os.getcwd(), '/', prefix, \".transloc\"])\n",
    "\n",
    "# make gmap index if not supplied by user\n",
    "else:\n",
    "    if not args.db_dir and not args.db_name:\n",
    "        print \"\\n ===Building GMAP database=== \"\n",
    "        try:\n",
    "            subprocess.call([gnavigator_path + '/build-index.sh', dbDir, dbName, genome])\n",
    "        except:\n",
    "            print 'Failed to build GMAP index.'\n",
    "            print 'Make sure that build-index.sh is in the same directory as gnavigator.'\n",
    "            sys.exit(1)\n",
    "\n",
    "# run gmap alignment\n",
    "    print \"\\n=== Performing GMAP alignments ===\"\n",
    "    try:\n",
    "        subprocess.call([gnavigator_path + '/run-gmap.sh', dbDir, dbName, threads, prefix, cDNA])\n",
    "    except:\n",
    "        print 'Failed to perform GMAP alignment.'\n",
    "        print 'Make sure that run-gmap.sh is in the same directory as gnavigator.'\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prefix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-99ec9a7528e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m              'blockcount', 'blocksizes', 'qstarts', 'tstarts']\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0muniqDat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'uniq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mduplDat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mult'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtlocDat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transloc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prefix' is not defined"
     ]
    }
   ],
   "source": [
    "# read in the data and define extent\n",
    "col_names = ['matches', 'mismatches', 'repmatches', 'ncount', 'qnuminsert', 'qbaseinsert', 'tnuminsert', \n",
    "             'tbaseinsert', 'strand', 'qname', 'qsize', 'qstart', 'qend', 'tname', 'tsize', 'tstart', 'tend',\n",
    "             'blockcount', 'blocksizes', 'qstarts', 'tstarts']\n",
    "\n",
    "uniqDat = pd.read_csv('.'.join([prefix, 'uniq']), sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "duplDat = pd.read_csv('.'.join([prefix, 'mult']), sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "tlocDat = pd.read_csv('.'.join([prefix, 'transloc']), sep='\\t', comment='#', low_memory=False, header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR DEV ###\n",
    "# read in the data and define extent\n",
    "col_names = ['matches', 'mismatches', 'repmatches', 'ncount', 'qnuminsert', 'qbaseinsert', 'tnuminsert', \n",
    "             'tbaseinsert', 'strand', 'qname', 'qsize', 'qstart', 'qend', 'tname', 'tsize', 'tstart', 'tend',\n",
    "             'blockcount', 'blocksizes', 'qstarts', 'tstarts']\n",
    "\n",
    "uniqDat = pd.read_csv('/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/runs/sitka-new-strategy-postLINKS-95.uniq', sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "duplDat = pd.read_csv('/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/runs/sitka-new-strategy-postLINKS-95.mult', sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "tlocDat = pd.read_csv('/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/runs/sitka-new-strategy-postLINKS-95.transloc', sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "### END DEV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in genetic map, if supplied\n",
    "# format for spruce map is LG\\tcM\\tcDNA\n",
    "if check_gm:\n",
    "    mapDat = pd.read_csv(gmfile, sep=\"\\t\", comment='#', low_memory=False, header=None, names=['LG', 'cM', 'cDNA'])\n",
    "    # limit genetic map analysis to complete (i.e. single) cDNAs to improve confidence\n",
    "    map_cDNA = set(mapDat.cDNA.tolist())\n",
    "    uniqDatMap = uniqDat[uniqDat.qname.isin(map_cDNA)]\n",
    "    uMap = uniqDatMap[uniqDatMap.tname.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup counters\n",
    "cDNA_res = {'Complete':[], 'Duplicated':[], 'Partial':[], 'Fragmented':[], 'Poorly mapped':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply check_complete to whole set\n",
    "for rec in uniqDat.itertuples():\n",
    "    res = check_aln(rec, 'assess')\n",
    "    cDNA_res[res[2]].append(res) # append results tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply check_frag to whole set\n",
    "for qry in tlocDat.qname.unique():\n",
    "    this_qry = tlocDat[tlocDat.qname == qry]\n",
    "    frags = []\n",
    "    for rec in this_qry.itertuples():\n",
    "        frags.append(rec)\n",
    "    \n",
    "    res = check_frag(frags)\n",
    "    cDNA_res[res[2]].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply check_dupl to whole set\n",
    "for qry in duplDat.qname.unique():\n",
    "    this_qry = duplDat[duplDat.qname == qry]\n",
    "    frags = []\n",
    "    for rec in this_qry.itertuples():\n",
    "        frags.append(rec)\n",
    "    \n",
    "    res = check_dupl(frags)\n",
    "    cDNA_res[res[2]].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR DEV ###\n",
    "cDNA = '/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/GCAT_WS-3.3.cluseq.noGaps.fa'\n",
    "gmfile = '/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/LM3-work-version-Feb2014_Jean_to_Inanc.txt'\n",
    "trim = True\n",
    "check_gm = True\n",
    "### END DEV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total number of query sequences\n",
    "check_missing = find_missing(cDNA, cDNA_res)\n",
    "TOT = check_missing[1]\n",
    "cDNA_res['Missing'] = check_missing[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GNAVIGATOR RESULTS ===\n",
      "9972 (36.74%) complete sequences\n",
      "2347 (8.65%) duplicated sequences\n",
      "4150 (15.29%) fragmented sequences\n",
      "3879 (14.29%) partial sequences\n",
      "5417 (19.96%) poorly mapped sequences\n",
      "1378 (5.08%) missing sequences\n",
      "27143 (100.0%) sequences were evaluated\n"
     ]
    }
   ],
   "source": [
    "# calc percentages and report results\n",
    "num_complete = len(cDNA_res['Complete'])\n",
    "num_duplicated = len(cDNA_res['Duplicated'])\n",
    "num_partial = len(cDNA_res['Partial'])\n",
    "num_fragmented = len(cDNA_res['Fragmented'])\n",
    "num_poor = len(cDNA_res['Poorly mapped'])\n",
    "num_missing = len(cDNA_res['Missing'])\n",
    "\n",
    "rate_complete = float(num_complete) / float(TOT)\n",
    "rate_duplicated = float(num_duplicated) / float(TOT)\n",
    "rate_partial = float(num_partial) / float(TOT)\n",
    "rate_fragmented = float(num_fragmented) / float(TOT)\n",
    "rate_poor = float(num_poor) / float(TOT)\n",
    "rate_missing = float(num_missing) / float(TOT)\n",
    "\n",
    "pct_complete = round(100.0 * rate_complete, 2)\n",
    "pct_duplicated = round(100.0 * rate_duplicated, 2)\n",
    "pct_partial = round(100.0 * rate_partial, 2)\n",
    "pct_fragmented = round(100 * rate_fragmented, 2)\n",
    "pct_poor = round(100 * rate_poor, 2)\n",
    "pct_missing = round(100 * rate_missing, 2)\n",
    "\n",
    "# report if the right number of sequences have a result\n",
    "num_counted = sum([num_complete, num_duplicated, num_fragmented, num_partial, num_poor, num_missing])\n",
    "rate_counted = float(num_counted) / float(TOT)\n",
    "pct_counted = round(100 * rate_counted, 2)\n",
    "\n",
    "# write to tsv\n",
    "tsvout = \"-\".join([prefix, \"results.tsv\"])\n",
    "with open(tsvout, \"w\") as outfile:\n",
    "    header = \"\\t\".join([\"\", \"Complete\", \"Duplicated\", \"Fragmented\", \"Partial\", \"Poorly Mapped\", \"Missing\", \"Total cDNAs searched\"])\n",
    "    nums = \"\\t\".join([str(x) for x in [\"Number\", num_complete, num_duplicated, num_fragmented, num_partial, num_poor, num_missing, num_counted]])\n",
    "    pcts = \"\\t\".join([str(x) for x in [\"Percent\", pct_complete, pct_duplicated, pct_fragmented, pct_partial, pct_poor, pct_missing, pct_counted]])\n",
    "\n",
    "    print >> outfile, header\n",
    "    print >> outfile, nums\n",
    "    print >> outfile, pcts\n",
    "\n",
    "jiraout = \"-\".join([prefix, \"results.jira\"])\n",
    "with open(jiraout, \"w\") as outfile:\n",
    "    header = \"||\".join([\"\", \"Complete\", \"Duplicated\", \"Fragmented\", \"Partial\", \"Poorly Mapped\", \"Missing\", \"Total cDNAs searched\", \"\"])\n",
    "    nums = [num_complete, num_duplicated, num_fragmented, num_partial, num_poor, num_missing, num_counted]\n",
    "    pcts = [pct_complete, pct_duplicated, pct_fragmented, pct_partial, pct_poor, pct_missing, pct_counted]\n",
    "    res = \"|\" + \"|\".join([jira_formatter(x) for x in zip(nums, pcts)]) + \"|\"\n",
    "    \n",
    "    print >> outfile, header\n",
    "    print >> outfile, res\n",
    "\n",
    "# print to STDOUT\n",
    "print \"\\n=== GNAVIGATOR RESULTS ===\"\n",
    "print \"%s (%s%%) complete sequences\" % (num_complete, pct_complete)\n",
    "print \"%s (%s%%) duplicated sequences\" % (num_duplicated, pct_duplicated)\n",
    "print \"%s (%s%%) fragmented sequences\" % (num_fragmented, pct_fragmented)\n",
    "print \"%s (%s%%) partial sequences\" % (num_partial, pct_partial)\n",
    "print \"%s (%s%%) poorly mapped sequences\" % (num_poor, pct_poor)\n",
    "print \"%s (%s%%) missing sequences\" % (num_missing, pct_missing)\n",
    "print \"%s (%s%%) sequences were evaluated\" % (num_counted, pct_counted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out cDNA:scaffold mappings\n",
    "header = \"\\t\".join([\"# cDNA ID\", \"Status\", \"Scaffold\"])\n",
    "full_out = \"-\".join([prefix, \"full-cDNA-results-table.tsv\"])\n",
    "with open(full_out, \"w\") as outfile:\n",
    "    print >> outfile, header\n",
    "    for status, result in cDNA_res.items():\n",
    "        for res in result:\n",
    "            for t in table_formatter(res):\n",
    "                print >> outfile, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply check_LG to whole uniq set\n",
    "if check_gm:\n",
    "    num_goodLG = 0 # same LG, right order\n",
    "    num_WO_LG = 0 # same LG, wrong order\n",
    "    num_diffLG = 0 # different LG\n",
    "\n",
    "    for rec in uMap.tname.unique():\n",
    "        thisScaf = uMap[uMap.tname.isin([rec])]\n",
    "        res = check_LG(thisScaf, mapDat)\n",
    "        if res == 'Same LG, right order':\n",
    "            num_goodLG += 1\n",
    "        elif res == 'Same LG, wrong order':\n",
    "            num_WO_LG += 1\n",
    "        elif res == 'Different LG':\n",
    "            num_diffLG += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "3923\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matches</th>\n",
       "      <th>mismatches</th>\n",
       "      <th>repmatches</th>\n",
       "      <th>ncount</th>\n",
       "      <th>qnuminsert</th>\n",
       "      <th>qbaseinsert</th>\n",
       "      <th>tnuminsert</th>\n",
       "      <th>tbaseinsert</th>\n",
       "      <th>strand</th>\n",
       "      <th>qname</th>\n",
       "      <th>...</th>\n",
       "      <th>qstart</th>\n",
       "      <th>qend</th>\n",
       "      <th>tname</th>\n",
       "      <th>tsize</th>\n",
       "      <th>tstart</th>\n",
       "      <th>tend</th>\n",
       "      <th>blockcount</th>\n",
       "      <th>blocksizes</th>\n",
       "      <th>qstarts</th>\n",
       "      <th>tstarts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1042</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1723</td>\n",
       "      <td>-</td>\n",
       "      <td>GQ0011_A20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1044</td>\n",
       "      <td>scaffold380298,12964,f368747Z12964</td>\n",
       "      <td>12964</td>\n",
       "      <td>3224</td>\n",
       "      <td>5991</td>\n",
       "      <td>5</td>\n",
       "      <td>717,113,82,105,27,</td>\n",
       "      <td>0,717,830,912,1017,</td>\n",
       "      <td>3224,4051,5610,5776,5964,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>897</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "      <td>GQ0011_A21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>scaffold92862,30623,f84051Z30623</td>\n",
       "      <td>30623</td>\n",
       "      <td>8205</td>\n",
       "      <td>9105</td>\n",
       "      <td>1</td>\n",
       "      <td>900,</td>\n",
       "      <td>0,</td>\n",
       "      <td>8205,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>919</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>GQ0011_B07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>931</td>\n",
       "      <td>scaffold23844,51116,f20500Z51116</td>\n",
       "      <td>51116</td>\n",
       "      <td>38906</td>\n",
       "      <td>39837</td>\n",
       "      <td>1</td>\n",
       "      <td>931,</td>\n",
       "      <td>3,</td>\n",
       "      <td>38906,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>897</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>-</td>\n",
       "      <td>GQ0011_B14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>911</td>\n",
       "      <td>scaffold873330,5354,f886980Z5354</td>\n",
       "      <td>5354</td>\n",
       "      <td>4181</td>\n",
       "      <td>5149</td>\n",
       "      <td>5</td>\n",
       "      <td>8,15,281,184,423,</td>\n",
       "      <td>0,8,23,304,488,</td>\n",
       "      <td>4181,4190,4206,4500,4726,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>705</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1110</td>\n",
       "      <td>-</td>\n",
       "      <td>GQ0011_B15</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>711</td>\n",
       "      <td>scaffold393698,12594,f382453Z12594</td>\n",
       "      <td>12594</td>\n",
       "      <td>7943</td>\n",
       "      <td>9760</td>\n",
       "      <td>6</td>\n",
       "      <td>291,107,75,97,11,126,</td>\n",
       "      <td>3,294,401,476,573,584,</td>\n",
       "      <td>7943,8733,9092,9342,9440,9634,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1256</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5354</td>\n",
       "      <td>-</td>\n",
       "      <td>GQ0011_C13</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1261</td>\n",
       "      <td>scaffold76587,33330,f68819Z33330</td>\n",
       "      <td>33330</td>\n",
       "      <td>18026</td>\n",
       "      <td>24640</td>\n",
       "      <td>7</td>\n",
       "      <td>19,408,94,156,60,219,304,</td>\n",
       "      <td>1,20,428,522,678,738,957,</td>\n",
       "      <td>18026,18046,18594,19119,20423,21237,24336,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   matches  mismatches  repmatches  ncount  qnuminsert  qbaseinsert  \\\n",
       "0     1042           2           0       0           0            0   \n",
       "1      897           3           0       0           0            0   \n",
       "2      919          12           0       0           0            0   \n",
       "3      897          14           0       0           0            0   \n",
       "4      705           2           0       0           0            0   \n",
       "5     1256           4           0       0           0            0   \n",
       "\n",
       "   tnuminsert  tbaseinsert strand       qname  \\\n",
       "0           4         1723      -  GQ0011_A20   \n",
       "1           0            0      +  GQ0011_A21   \n",
       "2           0            0      -  GQ0011_B07   \n",
       "3           4           57      -  GQ0011_B14   \n",
       "4           5         1110      -  GQ0011_B15   \n",
       "5           6         5354      -  GQ0011_C13   \n",
       "\n",
       "                      ...                      qstart  qend  \\\n",
       "0                     ...                           0  1044   \n",
       "1                     ...                           0   900   \n",
       "2                     ...                           0   931   \n",
       "3                     ...                           0   911   \n",
       "4                     ...                           4   711   \n",
       "5                     ...                           1  1261   \n",
       "\n",
       "                                tname  tsize  tstart   tend  blockcount  \\\n",
       "0  scaffold380298,12964,f368747Z12964  12964    3224   5991           5   \n",
       "1    scaffold92862,30623,f84051Z30623  30623    8205   9105           1   \n",
       "2    scaffold23844,51116,f20500Z51116  51116   38906  39837           1   \n",
       "3    scaffold873330,5354,f886980Z5354   5354    4181   5149           5   \n",
       "4  scaffold393698,12594,f382453Z12594  12594    7943   9760           6   \n",
       "5    scaffold76587,33330,f68819Z33330  33330   18026  24640           7   \n",
       "\n",
       "                  blocksizes                    qstarts  \\\n",
       "0         717,113,82,105,27,        0,717,830,912,1017,   \n",
       "1                       900,                         0,   \n",
       "2                       931,                         3,   \n",
       "3          8,15,281,184,423,            0,8,23,304,488,   \n",
       "4      291,107,75,97,11,126,     3,294,401,476,573,584,   \n",
       "5  19,408,94,156,60,219,304,  1,20,428,522,678,738,957,   \n",
       "\n",
       "                                      tstarts  \n",
       "0                   3224,4051,5610,5776,5964,  \n",
       "1                                       8205,  \n",
       "2                                      38906,  \n",
       "3                   4181,4190,4206,4500,4726,  \n",
       "4              7943,8733,9092,9342,9440,9634,  \n",
       "5  18026,18046,18594,19119,20423,21237,24336,  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### FOR DEV ###\n",
    "print num_goodLG\n",
    "print len(uniqDatMap)\n",
    "uniqDat[:6]\n",
    "### END DEV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GENETIC MAP GNAVIGATOR RESULTS ===\n",
      "83 (0.31%) scaffolds had 2+ complete cDNAs from the genetic map aligned to them.\n",
      "76 (91.57%) case(s) were from the same linkage group and in the expected order.\n",
      "1 (1.2%) case(s) were from the same linkage group, but NOT in the expected order.\n",
      "6 (7.23%) case(s) were from different linkage groups.\n"
     ]
    }
   ],
   "source": [
    "# report genetic map results\n",
    "if check_gm:\n",
    "    num_scaff_toCheck = len(uMap.tname.unique())\n",
    "    num_scaff_checked = num_goodLG + num_WO_LG + num_diffLG\n",
    "    if num_scaff_toCheck == num_scaff_checked:\n",
    "        rate_LGscaff = float(num_scaff_checked) / float(TOT)\n",
    "        rate_goodLG = float(num_goodLG) / float(num_scaff_checked)\n",
    "        rate_WO_LG = float(num_WO_LG) / float(num_scaff_checked)\n",
    "        rate_diffLG = float(num_diffLG) / float(num_scaff_checked)\n",
    "\n",
    "        pct_LGscaff = round(100.0 * rate_LGscaff, 2) \n",
    "        pct_goodLG = round(100.0 * rate_goodLG, 2)\n",
    "        pct_WO_LG = round(100.0 * rate_WO_LG, 2)\n",
    "        pct_diffLG = round(100.0 * rate_diffLG, 2)\n",
    "\n",
    "    else:\n",
    "        print 'Not all scaffolds to be checked against genetic map were successfully checked.'\n",
    "        print 'Maybe something is wrong with the input data?'\n",
    "        sys.exit(2)\n",
    "    \n",
    "    # write to tsv\n",
    "    tsvout = \"-\".join([prefix, \"genetic-map-results.tsv\"])\n",
    "    with open(tsvout, \"w\") as outfile:\n",
    "        header = \"\\t\".join([\"\", \"Same LG, right order\", \"Same LG, wrong order\", \"Different LG\", \"Total scaffolds analyzed\"])\n",
    "        nums = \"\\t\".join([str(x) for x in [\"Number\", num_goodLG, num_WO_LG, num_diffLG, num_scaff_checked]])\n",
    "        pcts = \"\\t\".join([str(x) for x in [\"Percent\", pct_goodLG, pct_WO_LG, pct_diffLG, pct_LGscaff]])\n",
    "\n",
    "        print >> outfile, header\n",
    "        print >> outfile, nums\n",
    "        print >> outfile, pcts\n",
    "\n",
    "    jiraout = \"-\".join([prefix, \"genetic-map-results.jira\"])\n",
    "    with open(jiraout, \"w\") as outfile:\n",
    "        header = \"||\".join([\"\", \"Same LG, right order\", \"Same LG, wrong order\", \"Different LG\", \"Total scaffolds analyzed\", \"\"])\n",
    "        nums = [num_goodLG, num_WO_LG, num_diffLG, num_scaff_checked]\n",
    "        pcts = [pct_goodLG, pct_WO_LG, pct_diffLG, pct_LGscaff]\n",
    "        res = \"|\" + \"|\".join([jira_formatter(x) for x in zip(nums, pcts)]) + \"|\"\n",
    "\n",
    "        print >> outfile, header\n",
    "        print >> outfile, res\n",
    "\n",
    "    print \"\\n=== GENETIC MAP GNAVIGATOR RESULTS ===\"\n",
    "    print \"%s (%s%%) scaffolds had 2+ complete cDNAs from the genetic map aligned to them.\" % (num_scaff_checked, pct_LGscaff)\n",
    "    print \"%s (%s%%) case(s) were from the same linkage group and in the expected order.\" % (num_goodLG, pct_goodLG)\n",
    "    print \"%s (%s%%) case(s) were from the same linkage group, but NOT in the expected order.\" % (num_WO_LG, pct_WO_LG)\n",
    "    print \"%s (%s%%) case(s) were from different linkage groups.\" % (num_diffLG, pct_diffLG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
