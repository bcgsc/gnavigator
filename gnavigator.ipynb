{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: The pandas module is required, but was not found. Please install and try again.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shammond/arch/CentOS_5/anaconda2/envs/jupyter/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# purpose: create a tool similar to CEGMA/BUSCO that uses genetic map information to assess \n",
    "#    completeness and quality of an assembly and reporting a simple set of metrics\n",
    "\n",
    "# want to distinguish complete, partial, fragmented, duplicated, poorly mapped, and missing\n",
    "# complete: 95% of sequence is aligned with 95% identity\n",
    "# partial: less than 95% of sequence is aligned to a single scaffold, other 5% unaligned\n",
    "# fragmented: 95% of a sequence is aligned, but over multiple scaffolds\n",
    "## would need to use check_aln in 'report' mode and assess separately\n",
    "## alignment would be reported in \"*.transloc\"\n",
    "# duplicated: as complete, but at multiple locations\n",
    "## alignment would be reported in \"*.mult\"\n",
    "# poorly mapped: as complete, partial, or fragmented, but with less than 95% identity\n",
    "# missing: not aligned by gmap\n",
    "## assessed separately\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import argparse\n",
    "from itertools import groupby\n",
    "from time import localtime, strftime\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    print 'ERROR: The pandas module is required, but was not found. Please install and try again.'\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "# return the sequence from the assembly that corresponds to the cDNA\n",
    "# report if any genetic map cDNAs should be found between cDNAs that are observed\n",
    "# add some wiggle room to the same LG, wrong order category. +/- 25bp?\n",
    "## should be handled by shuffling cDNAs with same cM location\n",
    "# quit upon gmap error\n",
    "# option to delete indices after use\n",
    "# set default %ident for inter- vs intra-species cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_aln(aln, mode):\n",
    "    \"\"\"check the alignment of a gcat map sequence\"\"\"\n",
    "\n",
    "    matches = float(aln.matches)\n",
    "    mismatches = float(aln.mismatches)\n",
    "    qinserts = float(aln.qbaseinsert)\n",
    "    qsize = float(aln.qsize)\n",
    "    qstart = float(aln.qstart)\n",
    "    qend = float(aln.qend)\n",
    "    scaf = str(aln.tname)\n",
    "    cDNA = str(aln.qname)\n",
    "    \n",
    "    seg = qend - qstart\n",
    "    pid = matches / seg\n",
    "    # want to penalize insertions b/c reflects correctness of assembly\n",
    "    pcov = (matches + mismatches - qinserts) / qsize\n",
    "    \n",
    "    if mode == 'assess':\n",
    "        if pid >= 0.95 and pcov >= 0.95:\n",
    "            return (cDNA, scaf, 'Complete')\n",
    "        elif pid >= 0.95 and pcov < 0.95:\n",
    "            if pcov >= 0.5:\n",
    "                return (cDNA, scaf, 'Partial')\n",
    "            else:\n",
    "                return (cDNA, scaf, 'Poorly mapped')\n",
    "        else:\n",
    "            return (cDNA, scaf, 'Poorly mapped')\n",
    "    \n",
    "    elif mode == 'report':\n",
    "        goodb = matches\n",
    "        # want to penalize insertions b/c reflects correctness of assembly\n",
    "        covb = matches + mismatches - qinserts\n",
    "        \n",
    "    return (goodb, covb, seg, qsize, cDNA, scaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_frag(alns):\n",
    "    \"\"\"check if 'chimeric' alignment is good or not\"\"\"\n",
    "    # take in a series of blat alignments and evaluate them together\n",
    "    # TODO extend to assess non-chimeric alignments\n",
    "    ## some cDNAs may be fragmented along >2 scaffolds, with some missing bits in the middle\n",
    "    goodb = 0\n",
    "    covb = 0\n",
    "    seg = 0\n",
    "    qsize = 0\n",
    "    cDNA = ''\n",
    "    scaf = []\n",
    "        \n",
    "    for aln in alns:\n",
    "        this_aln = check_aln(aln, 'report')\n",
    "        # check if a given alignment would otherwise qualify as complete\n",
    "        check_comp = check_aln(aln, 'assess')\n",
    "        if check_comp == 'Complete':\n",
    "            scaf = this_aln[5]\n",
    "            return (cDNA, scaf, 'Complete')\n",
    "        goodb += this_aln[0]\n",
    "        covb += this_aln[1]\n",
    "        seg += this_aln[2]\n",
    "        scaf.append(this_aln[5])\n",
    "    else:\n",
    "        qsize = this_aln[3]\n",
    "        cDNA = this_aln[4]\n",
    "    \n",
    "    pid = goodb / seg\n",
    "    pcov = covb / qsize\n",
    "    \n",
    "    scaf_rep = \";\".join(scaf)\n",
    "    if pid >= 0.95 and pcov >= 0.95:\n",
    "        return (cDNA, scaf_rep, 'Fragmented')\n",
    "    elif pid >= 0.95 and pcov < 0.95:\n",
    "        if pcov > 0.5:\n",
    "            return (cDNA, scaf_rep, 'Partial') # distinguish from partials in a single piece?\n",
    "        else:\n",
    "            return (cDNA, scaf_rep, 'Poorly mapped')\n",
    "    else:\n",
    "        return (cDNA, scaf_rep, 'Poorly mapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dupl(alns):\n",
    "    \"\"\"check if a gcat sequence should be considered duplicated or not based on its multiple alignments\"\"\"\n",
    "    # more than one alignment must be considered complete in order to be duplicated\n",
    "    # one or more partial, fragmented, poorly mapped will not count\n",
    "    cDNA = ''\n",
    "    scaf = []\n",
    "    results = {'Complete':[], 'Partial':[], 'Duplicated':[], 'Poorly mapped':[]}\n",
    "    for aln in alns:\n",
    "        this_aln = check_aln(aln, 'assess')\n",
    "        res = this_aln[-1]\n",
    "        results[res].append(this_aln)\n",
    "        scaf.append(this_aln[1])\n",
    "    else:\n",
    "        cDNA = this_aln[0]\n",
    "\n",
    "    scaf_rep = \";\".join(scaf)\n",
    "    num_complete = len(results['Complete'])\n",
    "    if num_complete == 1:\n",
    "        best_scaf = scaf[0]\n",
    "        return (cDNA, best_scaf, 'Complete')\n",
    "    elif num_complete > 1:\n",
    "        return (cDNA, scaf_rep, 'Duplicated')\n",
    "    else:\n",
    "        if len(results['Partial']) >= 1:\n",
    "            return (cDNA, scaf_rep, 'Partial')\n",
    "        else:\n",
    "            return (cDNA, scaf_rep, 'Poorly mapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_aligned(uniqA, duplA, tlocA):\n",
    "    \"\"\"count how many seqs have any alignment whatsoever\"\"\"\n",
    "    aligned = set()\n",
    "    for rec in uniqA.qname.unique():\n",
    "        aligned.add(rec)\n",
    "    for rec in duplA.qname.unique():\n",
    "        aligned.add(rec)\n",
    "    for rec in tlocA.qname.unique():\n",
    "        aligned.add(rec)\n",
    "        \n",
    "    return len(aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_LG(query, genetic_map):\n",
    "    \"\"\"check if cDNAs are from the same LG\"\"\"\n",
    "    # query is a pandas array of a single scaffold's alignments\n",
    "    # genetic_map is a pandas array of LG\\tcM\\tcDNA\n",
    "    # assume for now that cDNA is in genetic_map$cDNA\n",
    "    # returns 'same LG, right order', 'same LG, wrong order', or 'different LG'\n",
    "    refs = query.qname.tolist()\n",
    "    thisMap = genetic_map[genetic_map.cDNA.isin(refs)]\n",
    "    numLG = len(thisMap.LG.unique())\n",
    "    scaf = query.tname.unique()[0]\n",
    "    fwdA = query.sort_values(['tstart'])\n",
    "    fwdL = fwdA.qname.tolist()\n",
    "    revA = query.sort_values(['tstart'], ascending=False)\n",
    "    revL = revA.qname.tolist()\n",
    "    mapL = thisMap.cDNA.tolist()\n",
    "    cDNA_names = \";\".join(fwdL)\n",
    "    if len(thisMap) == 2:\n",
    "        if numLG == 1:\n",
    "            return (scaf, cDNA_names, 'Same LG, right order')\n",
    "        else:\n",
    "            return (scaf, cDNA_names, 'Different LG')\n",
    "    else:\n",
    "        if numLG == 1:\n",
    "            # comparing two lists of the same length will return True if order is the same\n",
    "            # compare both forward and reverse orders\n",
    "            if mapL == fwdL:\n",
    "                return (scaf, cDNA_names, 'Same LG, right order')\n",
    "            elif mapL == revL:\n",
    "                return (scaf, cDNA_names, 'Same LG, right order')\n",
    "            # some GM features have the same position in cM\n",
    "            # shuffle such features and check if they could match the alignments          \n",
    "            else:\n",
    "                checkcm = thisMap.groupby('cM')\n",
    "                else:\n",
    "                    return (scaf, cDNA_names, 'Same LG, wrong order')\n",
    "        else:\n",
    "            return (scaf, cDNA_names, 'Different LG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jira_formatter(num_pct_tuple):\n",
    "    # num_pct_tuple is tuple of (num, pct)\n",
    "    num = num_pct_tuple[0]\n",
    "    pct = num_pct_tuple[1]\n",
    "    outbuff = str(num) + \" \" + \"(\" + str(pct) + \"%)\"\n",
    "    return outbuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_formatter(results_tuple):\n",
    "    # results_tuple is from one of the check* functions\n",
    "    # (cDNA, scaffold, status), or (cDNA, scaffold1;scaffold2..., status)\n",
    "    nam = results_tuple[0]\n",
    "    scaf = results_tuple[1].split(\";\")\n",
    "    stat = results_tuple[2]\n",
    "    \n",
    "    for entry in scaf:\n",
    "        outbuff = \"\\t\".join([nam, stat, entry])\n",
    "        yield outbuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LG_table_formatter(results_tuple):\n",
    "    # results_tuple is from one of the check* functions\n",
    "    # (cDNA, scaffold, status), or (cDNA, scaffold1;scaffold2..., status)\n",
    "    nam = results_tuple[0]\n",
    "    cDNA = \" \".join(results_tuple[1].split(\";\"))\n",
    "    stat = results_tuple[2]\n",
    "    \n",
    "    outbuff = \"\\t\".join([nam, cDNA, stat])\n",
    "    yield outbuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fasta_iter\n",
    "#\n",
    "#   modified from code written by brentp and retrieved from https://www.biostars.org/p/710/ on May 5, 2015\n",
    "#   given a fasta file. yield tuples of header, sequence\n",
    "def fasta_iter(fasta_name):\n",
    "    # ditch the boolean (x[0]) and just keep the header or sequence since\n",
    "    # we know they alternate.\n",
    "    faiter = (x[1] for x in groupby(fasta_name, lambda line: line[0] == \">\"))\n",
    "    for header in faiter:\n",
    "        # drop the \">\"\n",
    "        header = header.next()[1:].strip()\n",
    "        # join all sequence lines to one.\n",
    "        seq = \"\".join(s.strip() for s in faiter.next())\n",
    "        yield header, seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing(fasta, res_dict):\n",
    "    # fasta is cDNA fasta\n",
    "    # res_dict is results dictionary like cDNA_res\n",
    "    # trim_flag corresponds to -a flag, passed to fasta_iter\n",
    "    ## will trim GenBank-style revision code from sequence IDs\n",
    "    cDNA_set = set()\n",
    "    with open(fasta, 'r') as infile:\n",
    "        for rec in fasta_iter(infile):\n",
    "            seqid = rec[0]\n",
    "            seqid_only = seqid.split(\" \")[0]\n",
    "            cDNA_set.add(seqid_only)\n",
    "    tot_cDNA = len(cDNA_set)\n",
    "\n",
    "    detected = set()\n",
    "    for key, value in res_dict.items():\n",
    "        resID = set([x[0] for x in value])\n",
    "        detected = detected.union(resID)\n",
    "\n",
    "    missing = cDNA_set.difference(detected)\n",
    "    missingL = [(x, 'NA', 'Missing') for x in missing]\n",
    "    \n",
    "    return (missingL, tot_cDNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_time():\n",
    "    rep = ' '.join([\"Current time:\", strftime(\"%Y-%m-%d %H:%M:%S\", localtime())])\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parser\n",
    "parser = argparse.ArgumentParser(description='Assess assembly quality and completeness using cDNA sequences')\n",
    "parser.add_argument('cDNA', help='FASTA file of cDNA sequences to align to assembly') # cDNA sequence fasta\n",
    "parser.add_argument('genome', help='FASTA file of genome assembly to assess')\n",
    "parser.add_argument('-p', '--prefix', help='Prefix to use for intermediate and output files [gnavigator]', default='gnavigator') # prefix\n",
    "parser.add_argument('-d', '--db_dir', help='Path to directory containing prebuilt GMAP index [optional]') # gmap db dir\n",
    "parser.add_argument('-n', '--db_name', help='Name of prebuilt GMAP index [optional]') # gmap db name\n",
    "parser.add_argument('-t', '--threads', help='Number of threads for GMAP alignment [1]', action='store', default='1')\n",
    "parser.add_argument('-m', '--genetic_map', help='Genetic map file as tsv with LG:cDNA pairs [optional]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process args\n",
    "args = parser.parse_args()\n",
    "cDNA = args.cDNA\n",
    "genome = args.genome\n",
    "prefix = args.prefix\n",
    "threads = args.threads\n",
    "\n",
    "if args.db_dir:\n",
    "    dbDir = args.db_dir\n",
    "else:\n",
    "    dbDir = ''.join([os.getcwd(), '/', prefix, '-gmap-index-dir'])\n",
    "if args.db_name:\n",
    "    dbName = args.db_name\n",
    "else:\n",
    "    dbName = '-'.join([prefix, 'gmap-index'])\n",
    "if args.genetic_map:\n",
    "    check_gm = True\n",
    "    gmfile = args.genetic_map\n",
    "else:\n",
    "    check_gm = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path to this script, and assume that the gmap sh scripts are there too\n",
    "gnavigator_path = re.sub('gnavigator.py', '', os.path.realpath(__file__))\n",
    "\n",
    "# check if alignments have already been done\n",
    "checkU = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".uniq\"]))\n",
    "checkM = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".mult\"]))\n",
    "checkD = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".transloc\"]))\n",
    "if checkU or checkM or checkD:\n",
    "    print \"\\n=== Skipping GMAP alignment stage ===\"\n",
    "    print \"Gnavigator found pre-existing GMAP alignment results. Will use the following files:\"\n",
    "    if checkU:\n",
    "        print ''.join([os.getcwd(), '/', prefix, \".uniq\"])\n",
    "    if checkM:\n",
    "        print ''.join([os.getcwd(), '/', prefix, \".mult\"])\n",
    "    if checkD:\n",
    "        print ''.join([os.getcwd(), '/', prefix, \".transloc\"])\n",
    "    print report_time()\n",
    "else:\n",
    "    # detect pre-existing index, use this check later (ref153positions is final index file created)\n",
    "    checkI = os.path.isfile(''.join([os.getcwd(), '/', prefix, '-gmap-index-dir/',\n",
    "                                     prefix, '-gmap-index/', prefix, '-gmap-index.ref153positions']))\n",
    "    # check if user supplied an index\n",
    "    if args.db_dir and args.db_name:\n",
    "        print \"\\n=== Skipping GMAP index construction ===\"\n",
    "        print \"Gnavigator will use the user-specified index:\"\n",
    "        print args.db_dir\n",
    "        print report_time()\n",
    "    # if not, check if index made already\n",
    "    elif checkI:\n",
    "        print \"\\n=== Skipping GMAP index construction ===\"\n",
    "        print \"Gnavigator found a pre-existing GMAP index:\"\n",
    "        print ''.join([os.getcwd(), '/', prefix, '-gmap-index-dir'])\n",
    "        print report_time()      \n",
    "    # otherwise, make gmap index\n",
    "    else:\n",
    "        print \"\\n=== Building GMAP database ===\"\n",
    "        print report_time()\n",
    "        try:\n",
    "            subprocess.call([gnavigator_path + '/build-index.sh', dbDir, dbName, genome])\n",
    "        except:\n",
    "            print 'Failed to build GMAP index.'\n",
    "            print 'Make sure that build-index.sh is in the same directory as gnavigator.'\n",
    "            sys.exit(1)\n",
    "    # run gmap alignment\n",
    "    print \"\\n=== Performing GMAP alignments ===\"\n",
    "    print report_time()\n",
    "    try:\n",
    "        subprocess.call([gnavigator_path + '/run-gmap.sh', dbDir, dbName, threads, prefix, cDNA])\n",
    "    except:\n",
    "        print 'Failed to perform GMAP alignment.'\n",
    "        print 'Make sure that run-gmap.sh is in the same directory as gnavigator.'\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which alignment files were produced\n",
    "checkU = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".uniq\"]))\n",
    "checkM = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".mult\"]))\n",
    "checkD = os.path.isfile(''.join([os.getcwd(), '/', prefix, \".transloc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data and define extent\n",
    "col_names = ['matches', 'mismatches', 'repmatches', 'ncount', 'qnuminsert', 'qbaseinsert', 'tnuminsert', \n",
    "             'tbaseinsert', 'strand', 'qname', 'qsize', 'qstart', 'qend', 'tname', 'tsize', 'tstart', 'tend',\n",
    "             'blockcount', 'blocksizes', 'qstarts', 'tstarts']\n",
    "if checkU:\n",
    "    uniqDat = pd.read_csv('.'.join([prefix, 'uniq']), sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "if checkM:\n",
    "    duplDat = pd.read_csv('.'.join([prefix, 'mult']), sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "if checkD:\n",
    "    tlocDat = pd.read_csv('.'.join([prefix, 'transloc']), sep='\\t', comment='#', low_memory=False, header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR DEV ###\n",
    "# read in the data and define extent\n",
    "col_names = ['matches', 'mismatches', 'repmatches', 'ncount', 'qnuminsert', 'qbaseinsert', 'tnuminsert', \n",
    "             'tbaseinsert', 'strand', 'qname', 'qsize', 'qstart', 'qend', 'tname', 'tsize', 'tstart', 'tend',\n",
    "             'blockcount', 'blocksizes', 'qstarts', 'tstarts']\n",
    "\n",
    "uniqDat = pd.read_csv('/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/runs/sitka-new-strategy-postLINKS-95.uniq', sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "duplDat = pd.read_csv('/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/runs/sitka-new-strategy-postLINKS-95.mult', sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "tlocDat = pd.read_csv('/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/runs/sitka-new-strategy-postLINKS-95.transloc', sep='\\t', comment='#', low_memory=False, header=None, names=col_names)\n",
    "### END DEV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in genetic map, if supplied\n",
    "# format for spruce map is LG\\tcM\\tcDNA\n",
    "if check_gm:\n",
    "    if not checkU:\n",
    "        print 'WARNING: There were no uniquely-aligned cDNAs detected, so the genetic map analysis will not be performed'\n",
    "    mapDat = pd.read_csv(gmfile, sep=\"\\t\", comment='#', low_memory=False, header=None, names=['LG', 'cM', 'cDNA'])\n",
    "    # limit genetic map analysis to complete (i.e. single) cDNAs to improve confidence\n",
    "    map_cDNA = set(mapDat.cDNA.tolist())\n",
    "    uniqDatMap = uniqDat[uniqDat.qname.isin(map_cDNA)]\n",
    "    uMap = uniqDatMap[uniqDatMap.tname.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup counters\n",
    "cDNA_res = {'Complete':[], 'Duplicated':[], 'Partial':[], 'Fragmented':[], 'Poorly mapped':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply check_complete to whole set\n",
    "if checkU:\n",
    "    for rec in uniqDat.itertuples():\n",
    "        res = check_aln(rec, 'assess')\n",
    "        cDNA_res[res[2]].append(res) # append results tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply check_frag to whole set\n",
    "if checkD:\n",
    "    for qry in tlocDat.qname.unique():\n",
    "        this_qry = tlocDat[tlocDat.qname == qry]\n",
    "        frags = []\n",
    "        for rec in this_qry.itertuples():\n",
    "            frags.append(rec)\n",
    "\n",
    "        res = check_frag(frags)\n",
    "        cDNA_res[res[2]].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply check_dupl to whole set\n",
    "if checkM:\n",
    "    for qry in duplDat.qname.unique():\n",
    "        this_qry = duplDat[duplDat.qname == qry]\n",
    "        frags = []\n",
    "        for rec in this_qry.itertuples():\n",
    "            frags.append(rec)\n",
    "\n",
    "        res = check_dupl(frags)\n",
    "        cDNA_res[res[2]].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR DEV ###\n",
    "cDNA = '/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/GCAT_WS-3.3.cluseq.noGaps.fa'\n",
    "gmfile = '/projects/btl/shammond/scratch/projects/genetic-map-assessment/gnavigator/LM3-work-version-Feb2014_Jean_to_Inanc.txt'\n",
    "trim = True\n",
    "check_gm = True\n",
    "### END DEV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total number of query sequences\n",
    "check_missing = find_missing(cDNA, cDNA_res)\n",
    "TOT = check_missing[1]\n",
    "cDNA_res['Missing'] = check_missing[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out cDNA:scaffold mappings\n",
    "header = \"\\t\".join([\"# cDNA ID\", \"Status\", \"Scaffold\"])\n",
    "full_out = \"-\".join([prefix, \"full-cDNA-results-table.tsv\"])\n",
    "with open(full_out, \"w\") as outfile:\n",
    "    print >> outfile, header\n",
    "    for status, result in cDNA_res.items():\n",
    "        for res in result:\n",
    "            for t in table_formatter(res):\n",
    "                print >> outfile, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc percentages and report results\n",
    "num_complete = len(cDNA_res['Complete'])\n",
    "num_duplicated = len(cDNA_res['Duplicated'])\n",
    "num_partial = len(cDNA_res['Partial'])\n",
    "num_fragmented = len(cDNA_res['Fragmented'])\n",
    "num_poor = len(cDNA_res['Poorly mapped'])\n",
    "num_missing = len(cDNA_res['Missing'])\n",
    "\n",
    "rate_complete = float(num_complete) / float(TOT)\n",
    "rate_duplicated = float(num_duplicated) / float(TOT)\n",
    "rate_partial = float(num_partial) / float(TOT)\n",
    "rate_fragmented = float(num_fragmented) / float(TOT)\n",
    "rate_poor = float(num_poor) / float(TOT)\n",
    "rate_missing = float(num_missing) / float(TOT)\n",
    "\n",
    "pct_complete = round(100.0 * rate_complete, 2)\n",
    "pct_duplicated = round(100.0 * rate_duplicated, 2)\n",
    "pct_partial = round(100.0 * rate_partial, 2)\n",
    "pct_fragmented = round(100 * rate_fragmented, 2)\n",
    "pct_poor = round(100 * rate_poor, 2)\n",
    "pct_missing = round(100 * rate_missing, 2)\n",
    "\n",
    "# report if the right number of sequences have a result\n",
    "num_counted = sum([num_complete, num_duplicated, num_fragmented, num_partial, num_poor, num_missing])\n",
    "rate_counted = float(num_counted) / float(TOT)\n",
    "pct_counted = round(100 * rate_counted, 2)\n",
    "\n",
    "# write to tsv\n",
    "tsvout = \"-\".join([prefix, \"results.tsv\"])\n",
    "with open(tsvout, \"w\") as outfile:\n",
    "    header = \"\\t\".join([\"\", \"Complete\", \"Duplicated\", \"Fragmented\", \"Partial\", \"Poorly Mapped\", \"Missing\", \"Total cDNAs searched\"])\n",
    "    nums = \"\\t\".join([str(x) for x in [\"Number\", num_complete, num_duplicated, num_fragmented, num_partial, num_poor, num_missing, num_counted]])\n",
    "    pcts = \"\\t\".join([str(x) for x in [\"Percent\", pct_complete, pct_duplicated, pct_fragmented, pct_partial, pct_poor, pct_missing, pct_counted]])\n",
    "\n",
    "    print >> outfile, header\n",
    "    print >> outfile, nums\n",
    "    print >> outfile, pcts\n",
    "\n",
    "jiraout = \"-\".join([prefix, \"results.jira\"])\n",
    "with open(jiraout, \"w\") as outfile:\n",
    "    header = \"||\".join([\"\", \"Complete\", \"Duplicated\", \"Fragmented\", \"Partial\", \"Poorly Mapped\", \"Missing\", \"Total cDNAs searched\", \"\"])\n",
    "    nums = [num_complete, num_duplicated, num_fragmented, num_partial, num_poor, num_missing, num_counted]\n",
    "    pcts = [pct_complete, pct_duplicated, pct_fragmented, pct_partial, pct_poor, pct_missing, pct_counted]\n",
    "    res = \"|\" + \"|\".join([jira_formatter(x) for x in zip(nums, pcts)]) + \"|\"\n",
    "    \n",
    "    print >> outfile, header\n",
    "    print >> outfile, res\n",
    "\n",
    "# print to STDOUT\n",
    "print \"\\n=== GNAVIGATOR cDNA RESULTS ===\"\n",
    "print \"%s (%s%%) complete sequences\" % (num_complete, pct_complete)\n",
    "print \"%s (%s%%) duplicated sequences\" % (num_duplicated, pct_duplicated)\n",
    "print \"%s (%s%%) fragmented sequences\" % (num_fragmented, pct_fragmented)\n",
    "print \"%s (%s%%) partial sequences\" % (num_partial, pct_partial)\n",
    "print \"%s (%s%%) poorly mapped sequences\" % (num_poor, pct_poor)\n",
    "print \"%s (%s%%) missing sequences\" % (num_missing, pct_missing)\n",
    "print \"%s (%s%%) sequences were evaluated\" % (num_counted, pct_counted)\n",
    "print report_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply check_LG to whole uniq set\n",
    "if check_gm:\n",
    "    # check if there's anything to work with\n",
    "    if len(uniqDatMap) == 0:\n",
    "        print \"ERROR: There are no cDNAs from the genetic map to evaluate.\"\n",
    "        print \"This can happen if the cDNA sequence IDs do not match those in the genetic map.\"\n",
    "        sys.exit(2)\n",
    "    gm_res = {'goodLG':[], 'WO_LG':[], 'diffLG':[]}\n",
    "    #num_goodLG = 0 # same LG, right order\n",
    "    #num_WO_LG = 0 # same LG, wrong order\n",
    "    #num_diffLG = 0 # different LG\n",
    "\n",
    "    for rec in uMap.tname.unique():\n",
    "        thisScaf = uMap[uMap.tname.isin([rec])]\n",
    "        res = check_LG(thisScaf, mapDat)\n",
    "        rep = res[2]\n",
    "        if rep == 'Same LG, right order':\n",
    "            gm_res['goodLG'].append(res)\n",
    "            #num_goodLG += 1\n",
    "        elif rep == 'Same LG, wrong order':\n",
    "            gm_res['WO_LG'].append(res)\n",
    "            #num_WO_LG += 1\n",
    "        elif rep == 'Different LG':\n",
    "            gm_res['diffLG'].append(res)\n",
    "            #num_diffLG += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR DEV ###\n",
    "print num_goodLG\n",
    "print len(uniqDatMap)\n",
    "uniqDat[:6]\n",
    "### END DEV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write cDNA:scaffold LG results to file\n",
    "if check_gm:\n",
    "    header = \"\\t\".join([\"# Scaffold\", \"cDNA IDs\", \"Status\"])\n",
    "    full_out = \"-\".join([prefix, \"full-genetic-map-results-table.tsv\"])\n",
    "    with open(full_out, \"w\") as outfile:\n",
    "        print >> outfile, header\n",
    "        for status, result in gm_res.items():\n",
    "            for res in result:\n",
    "                for t in LG_table_formatter(res):\n",
    "                    print >> outfile, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report summary of genetic map results\n",
    "if check_gm:\n",
    "    num_scaff_toCheck = len(uMap.tname.unique())\n",
    "    num_goodLG = len(gm_res['goodLG'])\n",
    "    num_WO_LG = len(gm_res['WO_LG'])\n",
    "    num_diffLG = len(gm_res['diffLG'])\n",
    "    num_scaff_checked = num_goodLG + num_WO_LG + num_diffLG\n",
    "    if num_scaff_toCheck == num_scaff_checked:\n",
    "        rate_LGscaff = float(num_scaff_checked) / float(TOT)\n",
    "        rate_goodLG = float(num_goodLG) / float(num_scaff_checked)\n",
    "        rate_WO_LG = float(num_WO_LG) / float(num_scaff_checked)\n",
    "        rate_diffLG = float(num_diffLG) / float(num_scaff_checked)\n",
    "\n",
    "        pct_LGscaff = round(100.0 * rate_LGscaff, 2) \n",
    "        pct_goodLG = round(100.0 * rate_goodLG, 2)\n",
    "        pct_WO_LG = round(100.0 * rate_WO_LG, 2)\n",
    "        pct_diffLG = round(100.0 * rate_diffLG, 2)\n",
    "\n",
    "    else:\n",
    "        print 'Not all scaffolds to be checked against genetic map were successfully checked.'\n",
    "        print 'Maybe something is wrong with the input data?'\n",
    "        print report_time()\n",
    "        sys.exit(2)\n",
    "    \n",
    "    # write to tsv\n",
    "    tsvout = \"-\".join([prefix, \"genetic-map-results.tsv\"])\n",
    "    with open(tsvout, \"w\") as outfile:\n",
    "        header = \"\\t\".join([\"\", \"Same LG, right order\", \"Same LG, wrong order\", \"Different LG\", \"Total scaffolds analyzed\"])\n",
    "        nums = \"\\t\".join([str(x) for x in [\"Number\", num_goodLG, num_WO_LG, num_diffLG, num_scaff_checked]])\n",
    "        pcts = \"\\t\".join([str(x) for x in [\"Percent\", pct_goodLG, pct_WO_LG, pct_diffLG, pct_LGscaff]])\n",
    "\n",
    "        print >> outfile, header\n",
    "        print >> outfile, nums\n",
    "        print >> outfile, pcts\n",
    "\n",
    "    jiraout = \"-\".join([prefix, \"genetic-map-results.jira\"])\n",
    "    with open(jiraout, \"w\") as outfile:\n",
    "        header = \"||\".join([\"\", \"Same LG, right order\", \"Same LG, wrong order\", \"Different LG\", \"Total scaffolds analyzed\", \"\"])\n",
    "        nums = [num_goodLG, num_WO_LG, num_diffLG, num_scaff_checked]\n",
    "        pcts = [pct_goodLG, pct_WO_LG, pct_diffLG, pct_LGscaff]\n",
    "        res = \"|\" + \"|\".join([jira_formatter(x) for x in zip(nums, pcts)]) + \"|\"\n",
    "\n",
    "        print >> outfile, header\n",
    "        print >> outfile, res\n",
    "\n",
    "    print \"\\n=== GNAVIGATOR GENETIC MAP RESULTS ===\"\n",
    "    print \"%s (%s%%) scaffolds had 2+ complete cDNAs from the genetic map aligned to them.\" % (num_scaff_checked, pct_LGscaff)\n",
    "    print \"%s (%s%%) case(s) were from the same linkage group and in the expected order.\" % (num_goodLG, pct_goodLG)\n",
    "    print \"%s (%s%%) case(s) were from the same linkage group, but NOT in the expected order.\" % (num_WO_LG, pct_WO_LG)\n",
    "    print \"%s (%s%%) case(s) were from different linkage groups.\" % (num_diffLG, pct_diffLG)\n",
    "    print report_time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
